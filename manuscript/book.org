#+TITLE: Functional Programming for Mortals with Scalaz
#+AUTHOR: Sam Halliday
#+DATE: 2017

#+TAGS: ME OTHER
#+TODO: TODO | RESEARCH | NOTES | CHART | DIAGRAM | DRAWING | CODE | VIDEO
#+OPTIONS: toc:nil

# Σ ⊣ Δ ⊣ Π

* Frontmatter                                                         :final:
:PROPERTIES:
:EXPORT_FILE_NAME: frontmatter.md
:END:
{frontmatter}

#+BEGIN_QUOTE
"Love is wise; hatred is foolish. In this world, which is getting more
and more closely interconnected, we have to learn to tolerate each
other, we have to learn to put up with the fact that some people say
things that we don't like. We can only live together in that way. But
if we are to live together, and not die together, we must learn a kind
of charity and a kind of tolerance, which is absolutely vital to the
continuation of human life on this planet."

― Bertrand Russell
#+END_QUOTE

** About This Book

This book is for Scala developers with a Java background who wish to
learn the *Functional Programming* (FP) paradigm. We do not accept
that the merits of FP are obvious. Therefore, this book justifies
every concept with practical examples, in Scala.

There are many ways to do Functional Programming in Scala. This book
focuses on using [[https://github.com/scalaz/scalaz][scalaz]], but you can instead use [[http://typelevel.org/cats/][cats]] or roll your own
framework.

This book is designed to be read from cover to cover, in the order
presented, with a rest between chapters. To ensure that the book is
concise, important concepts are not always repeated. Re-read sections
that are confusing, they will be important later.

A computer is not necessary to follow along, although we hope that you
will gain the confidence to independently study the scalaz source
code.

We also recommend [[https://www.manning.com/books/functional-programming-in-scala][The Red Book]] as further reading. It teaches how to
write an FP library in Scala from first principles.

** Copyleft Notice

This book is *Libre* and follows the philosophy of [[https://www.gnu.org/philosophy/free-sw.en.html][Free Software]]: you
can use this book as you like, the [[https://github.com/fommil/fp-scala-mortals][source is available]], you can
redistribute this book and you can distribute your own version. That
means you can print it, photocopy it, e-mail it, upload it to
websites, change it, translate it, remix it, delete bits, and draw all
over it.

You can even sell this book or your own version (although, morally,
you should offer a royalty share to the author). If you received this
book without paying for it, I would appreciate it if you donated what
you feel it is worth at https://leanpub.com/fpmortals.

This book is *Copyleft*: if you change the book and distribute your
own version, you must also pass these freedoms to its recipients.

This book uses the [[https://creativecommons.org/licenses/by-sa/4.0/legalcode][Creative Commons Attribution ShareAlike 4.0
International]] (CC BY-SA 4.0) license.

All original code snippets in this book are separately [[https://wiki.creativecommons.org/wiki/CC0][CC0]] licensed,
you may use them without restriction. Excerpts from =scalaz= and
related libraries maintain their license, reproduced in full in the
appendix.

The example application =drone-dynamic-agents= is distributed under
the terms of the [[https://www.gnu.org/licenses/gpl-3.0.en.html][GPLv3]]: only the snippets in this book are available
without restriction.

** Thanks

Diego Esteban Alonso Blas, Raúl Raja Martínez and Peter Neyens of 47
degrees, Rúnar Bjarnason and Tony Morris for their help explaining the
principles of FP. Kenji Yoshida and Jason Zaugg for being the main
authors of scalaz, and Miles Sabin for implementing critical FP
features in the scala compiler.

The readers who gave feedback on early drafts of this text.

Juan Manuel Serrano for [[https://skillsmatter.com/skillscasts/9904-london-scala-march-meetup#video][All Roads Lead to Lambda]], Pere Villega for [[http://perevillega.com/understanding-free-monads][On
Free Monads]], Dick Wall and Josh Suereth for [[https://www.youtube.com/watch?v=WDaw2yXAa50][For: What is it Good For?]],
John de Goes for [[http://degoes.net/articles/easy-monads][A Beginner Friendly Tour]], Erik Bakker for [[https://www.youtube.com/watch?v=hGMndafDcc8][Options in
Futures, how to unsuck them]], Noel Markham for [[https://www.47deg.com/presentations/2017/06/01/ADT-for-the-win/][ADTs for the Win!]], Adam
Rosien for the [[http://arosien.github.io/scalaz-cheatsheets/typeclasses.pdf][Scalaz Cheatsheet]], Yi Lin Wei and Zainab Ali for their
tutorials at Hack The Tower meetups.

The helpul souls who patiently explained the concepts needed to write
the example project [[https://gitlab.com/fommil/drone-dynamic-agents][drone-dynamic-agents]] Merlin Göttlinger, Edmund
Noble, Fabio Labella, Vincent Marquez, Adelbert Chang, Kai(luo) Wang,
Michael Pilquist, Adam Chlupacek, Pavel Chlupacek, Paul Snively,
Daniel Spiewak, Stephen Compall.

** Practicalities

If you'd like to set up a project that uses the libraries presented in
this book, you will need to use a recent version of Scala with
FP-specific features enabled (e.g. in =build.sbt=):

#+BEGIN_SRC scala
scalaVersion in ThisBuild := "2.12.3"
scalacOptions in ThisBuild ++= Seq(
  "-language:_",
  "-Ypartial-unification",
  "-Xfatal-warnings"
)

libraryDependencies ++= Seq(
  "com.github.mpilquist" %% "simulacrum"  % "0.11.0",
  "com.chuusai"          %% "shapeless"   % "2.3.2" ,
  "com.fommil"           %% "stalactite"  % "0.0.4" ,
  "org.scalaz"           %% "scalaz-core" % "7.2.15"
)

addCompilerPlugin("org.spire-math" %% "kind-projector" % "0.9.4")
addCompilerPlugin(
  "org.scalamacros" % "paradise" % "2.1.1" cross CrossVersion.full
)
#+END_SRC

In order to keep our snippets short, we will omit the =import=
section. Unless told otherwise, assume that all snippets have the
following imports:

#+BEGIN_SRC scala
import scalaz._, Scalaz._
import simulacrum._
import stalactite._
#+END_SRC

** Giving Feedback

You are reading an Early Access version of this book. You will have
access to the final version of the book, expected in 2018, at no
additional cost.

Please help raise awareness of this book by telling your friends,
especially the most sceptical.

If you would like to give feedback on this book, thank you! I ask of
you:

1. if you are an FP beginner and something confused you, please point
   out the exact part of the text that confused you at
   [[https://github.com/fommil/fp-scala-mortals/issues][fommil/fpmortals]]
2. if you are an expert in FP, please help by answering my questions
   at [[https://gitlab.com/fommil/drone-dynamic-agents/issues][fommil/drone-dynamic-agents]] and pointing out factual errors in
   this text.
3. if you understood a concept, but feel that it could be explained in
   a different way, let's park that thought for now.
4. grammatical errors and typos will (eventually) be corrected by an
   editor, they do not need to be reported.

* Mainmatter                                                          :final:
:PROPERTIES:
:EXPORT_FILE_NAME: mainmatter.md
:END:
{mainmatter}

* Introduction                                                        :final:
  :PROPERTIES:
  :EXPORT_FILE_NAME: introduction.md
  :END:
** Introduction

It is human instinct to be sceptical of a new paradigm. To put some
perspective on how far we have come, and the shifts we have already
accepted on the JVM, let's start with a quick recap of the last 20
years.

Java 1.2 introduced the Collections API, allowing us to write methods
that abstracted over mutable collections. It was useful for writing
general purpose algorithms and was the bedrock of our codebases.

But there was a problem, we had to perform runtime casting:

#+BEGIN_SRC java
public String first(Collection collection) {
  return (String)(collection.get(0));
}
#+END_SRC

In response, developers defined domain objects in their business logic
that were effectively =CollectionOfThings=, and the Collection API
became implementation detail.

In 2005, Java 5 introduced /generics/, allowing us to define
=Collection<Thing>=, abstracting over the container *and* its
elements. Generics changed how we wrote Java.

The author of the Java generics compiler, Martin Odersky, then created
Scala with a stronger type system, immutable data and multiple
inheritance. This brought about a fusion of object oriented (OOP) and
functional programming (FP).

For most developers, FP means using immutable data as much as
possible, but mutable state is still a necessary evil that must be
isolated and managed, e.g. with Akka actors or =synchronized= classes.
This style of FP results in simpler programs that are easier to
parallelise and distribute, an improvement over Java. But it is only
scratching the surface of the benefits of FP, as we'll discover in
this book.

Scala also brings =Future=, making it easy to write asynchronous
applications. But when a =Future= makes it into a return type,
/everything/ needs to be rewritten to accomodate it, including the
tests, which are now subject to arbitrary timeouts.

We have a problem similar to Java 1.0: there is no way of abstracting
over execution, much as we had no way of abstracting over collections.

*** Abstracting over Execution

Let's say we want to interact with the user over the command line
interface. We can =read= what the user types and we can =write= a
message to them.

#+BEGIN_SRC scala
trait TerminalSync {
  def read(): String
  def write(t: String): Unit
}

trait TerminalAsync {
  def read(): Future[String]
  def write(t: String): Future[Unit]
}
#+END_SRC

But how do we write generic code that does something as simple as echo
the user's input synchronously or asynchronously depending on our
runtime implementation?

We could write a synchronous version and wrap it with =Future= but now
we have to worry about which thread pool we should be using for the
work, or we could =Await.result= on the =Future= and introduce thread
blocking. In either case, it's a lot of boilerplate and we are
fundamentally dealing with different APIs that are not unified.

Let's try to solve the problem like Java 1.2 by introducing a common
parent. To do this, we need to use the /higher kinded types/ Scala
language feature.

#+BEGIN_ASIDE

*Higher Kinded Types* allow us to use a /type constructor/ in our type
parameters, which looks like =C[_]=. This is a way of saying that
whatever =C= is, it must take a type parameter. For example:

#+BEGIN_SRC scala
trait Foo[C[_]] {
  def create(i: Int): C[Int]
}
#+END_SRC

=List= is a type constructor because it takes a type (e.g. =Int=) and
constructs a type (=List -> Int -> List[Int]=). We can implement =Foo=
using =List=:

#+BEGIN_SRC scala
object FooList extends Foo[List] {
  def create(i: Int): List[Int] = List(i)
}
#+END_SRC

We can implement =Foo= for anything with a type parameter hole, e.g.
=Either[String, _]=. Unfortunately it is a bit clunky and we have to
create a type alias to trick the compiler into accepting it:

#+BEGIN_SRC scala
type EitherString[T] = Either[String, T]
#+END_SRC

Type aliases don't define new types, they just use substitution and
don't provide extra type safety. The compiler substitutes
=EitherString[T]= with =Either[String, T]= everywhere. This technique
can be used to trick the compiler into accepting types with one hole
when it would otherwise think there are two, like when we implement
=Foo= with =EitherString=:

#+BEGIN_SRC scala
object FooEitherString extends Foo[EitherString] {
 def create(i: Int): Either[String, Int] = Right(i)
}
#+END_SRC

Alternatively, the [[https://github.com/non/kind-projector/][kind projector]] plugin allows us to avoid the =type=
alias and use =?= syntax to tell the compiler where the type hole is:

#+BEGIN_SRC scala
object FooEitherString extends Foo[Either[String, ?]] {
 def create(i: Int): Either[String, Int] = Right(i)
}
#+END_SRC

Finally, there is this one weird trick we can use when we want to
ignore the type constructor. Let's define a type alias to be equal to
its parameter:

#+BEGIN_SRC scala
type Id[T] = T
#+END_SRC

Before proceeding, convince yourself that =Id[Int]= is the same thing
as =Int=, by substituting =Int= into =T=. Because =Id= is a valid type
constructor we can use =Id= in an implementation of =Foo=

#+BEGIN_SRC scala
object FooId extends Foo[Id] {
  def create(i: Int): Int = i
}
#+END_SRC

#+END_ASIDE

We want to define =Terminal= for a type constructor =C[_]=. By
defining =Now= to construct to its type parameter (like =Id=), we can
implement a common interface for synchronous and asynchronous
terminals:

#+BEGIN_SRC scala
trait Terminal[C[_]] {
  def read: C[String]
  def write(t: String): C[Unit]
}

type Now[X] = X

object TerminalSync extends Terminal[Now] {
  def read: String = ???
  def write(t: String): Unit = ???
}

object TerminalAsync extends Terminal[Future] {
  def read: Future[String] = ???
  def write(t: String): Future[Unit] = ???
}
#+END_SRC

You can think of =C= as a /Context/ because we say "in the context of
executing =Now=" or "in the =Future=".

But we know nothing about =C= and we can't do anything with a
=C[String]=. What we need is a kind of execution environment that lets
us call a method returning =C[T]= and then be able to do something
with the =T=, including calling another method on =Terminal=. We also
need a way of wrapping a value as a =C[_]=. This signature works well:

#+BEGIN_SRC scala
trait Execution[C[_]] {
  def doAndThen[A, B](c: C[A])(f: A => C[B]): C[B]
  def create[B](b: B): C[B]
}
#+END_SRC

letting us write:

#+BEGIN_SRC scala
def echo[C[_]](t: Terminal[C], e: Execution[C]): C[String] =
  e.doAndThen(t.read) { in: String =>
    e.doAndThen(t.write(in)) { _: Unit =>
      e.create(in)
    }
  }
#+END_SRC

We can now share the =echo= implementation between synchronous and
asynchronous codepaths. We can write a mock implementation of
=Terminal[Now]= and use it in our tests without any timeouts.

Implementations of =Execution[Now]= and =Execution[Future]= are
reusable by generic methods like =echo=.

But the code for =echo= is horrible! Let's clean it up.

The =implicit class= Scala language feature gives =C= some methods.
We'll call these methods =flatMap= and =map= for reasons that will
become clearer in a moment. Each method takes an =implicit
Execution[C]=, but this is nothing more than the =flatMap= and =map=
that you're used to on =Seq=, =Option= and =Future=

#+BEGIN_SRC scala
object Execution {
  implicit class Ops[A, C[_]](c: C[A]) {
    def flatMap[B](f: A => C[B])(implicit e: Execution[C]): C[B] =
          e.doAndThen(c)(f)
    def map[B](f: A => B)(implicit e: Execution[C]): C[B] =
          e.doAndThen(c)(f andThen e.create)
  }
}

def echo[C[_]](implicit t: Terminal[C], e: Execution[C]): C[String] =
  t.read.flatMap { in: String =>
    t.write(in).map { _: Unit =>
      in
    }
  }
#+END_SRC

We can now reveal why we used =flatMap= as the method name: it lets us
use a /for comprehension/, which is just syntax sugar over nested
=flatMap= and =map=.

#+BEGIN_SRC scala
def echo[C[_]](implicit t: Terminal[C], e: Execution[C]): C[String] =
  for {
    in <- t.read
     _ <- t.write(in)
  } yield in
#+END_SRC

Our =Execution= has the same signature as a trait in scalaz called
=Monad=, except =doAndThen= is =flatMap= and =create= is =pure=. We
say that =C= is /monadic/ when there is an implicit =Monad[C]=
available. In addition, scalaz has the =Id= type alias.

The takeaway is: if we write methods that operate on monadic types,
then we can write sequential code that abstracts over its execution
context. Here, we have shown an abstraction over synchronous and
asynchronous execution but it can also be for the purpose of more
rigorous error handling (where =C[_]= is =Either[Error, _]=), managing
access to volatile state, performing I/O, or auditing of the session.

*** Pure Functional Programming

FP functions have three key properties:

- *Totality* return a value for every possible input
- *Determinism* return the same value for the same input
- *Purity* the only effect is the computation of a return value.

Together, these properties give us an unprecedented ability to reason
about our code. Caching is easier to understand with determinism and
purity, and input validation is easier to isolate with totality.

The kinds of things that break these properties are /side effects/:
accessing or changing mutable state (e.g. generating random numbers,
maintaining a =var= in a class), communicating with external resources
(e.g. files or network lookup), or throwing exceptions.

But in Scala, we perform side effects all the time. A call to
=log.info= will perform I/O and a call to =asString= on a =Http=
instance will speak to a web server. It's fair to say that typical
Scala is *not* FP.

However, something beautiful happened when we wrote our implementation
of =echo=. Anything that depends on state or external resources is
provided as an explicit input: our functions are deterministic and
pure. We not only get to abstract over execution environment, but we
also get to dramatically improve the repeatability - and performance -
of our tests. We are free to implement =Terminal= without any
interactions with a real console.

Of course we cannot write an application devoid of interaction with
the world. In FP we push the code that deals with side effects to the
edges. That kind of code can use battle-tested libraries like NIO,
Akka and Play, isolated away from the core business logic.

This book expands on the FP style introduced in this chapter. We're
going to use the traits and classes defined in the /scalaz/ and /fs2/
libraries to implement streaming applications. We'll also use
developer tooling to eliminate some of the boilerplate we've already
seen in this chapter, allowing you to focus on writing pure business
logic.

* Complete                                                            :final:
  :PROPERTIES:
  :EXPORT_FILE_NAME: complete.md
  :END:
** For Comprehensions

Scala's =for= comprehension is the ideal FP abstraction for sequential
programs that interact with the world. Since we'll be using it a lot,
we're going to relearn the principles of =for= and how scalaz can help
us to write cleaner code.

This chapter doesn't try to write pure programs and the techniques are
applicable to non-FP codebases.

*** Syntax Sugar

Scala's =for= is just a simple rewrite rule, also called /syntax
sugar/, that doesn't have any contextual information.

To see what a =for= comprehension is doing, we use the =show= and
=reify= feature in the REPL to print out what code looks like after
type inference.

#+BEGIN_SRC scala
scala> import scala.reflect.runtime.universe._
scala> val a, b, c = Option(1)
scala> show { reify {
         for { i <- a ; j <- b ; k <- c } yield (i + j + k)
       } }

res:
$read.a.flatMap(
  ((i) => $read.b.flatMap(
    ((j) => $read.c.map(
      ((k) => i.$plus(j).$plus(k)))))))
#+END_SRC

There is a lot of noise due to additional sugarings (e.g. =+= is
rewritten =$plus=, etc). We'll skip the =show= and =reify= for brevity
when the REPL line is =reify>=, and manually clean up the generated
code so that it doesn't become a distraction.

#+BEGIN_SRC scala
reify> for { i <- a ; j <- b ; k <- c } yield (i + j + k)

a.flatMap {
  i => b.flatMap {
    j => c.map {
      k => i + j + k }}}
#+END_SRC

The rule of thumb is that every =<-= (called a /generator/) is a
nested =flatMap= call, with the final generator a =map= containing the
=yield= body.

**** Assignment

We can assign values inline like =ij = i + j= (a =val= keyword is not
needed).

#+BEGIN_SRC scala
reify> for {
         i <- a
         j <- b
         ij = i + j
         k <- c
       } yield (ij + k)

a.flatMap {
  i => b.map { j => (j, i + j) }.flatMap {
    case (j, ij) => c.map {
      k => ij + k }}}
#+END_SRC

A =map= over the =b= introduces the =ij= which is flat-mapped along
with the =j=, then the final =map= for the code in the =yield=.

Unfortunately we cannot assign before any generators. It has been
requested as a language feature but has not been implemented:
https://github.com/scala/bug/issues/907

#+BEGIN_SRC scala
scala> for {
         initial = getDefault
         i <- a
       } yield initial + i
<console>:1: error: '<-' expected but '=' found.
#+END_SRC

We can workaround the limitation by defining a =val= outside the =for=

#+BEGIN_SRC scala
scala> val initial = getDefault
scala> for { i <- a } yield initial + i
#+END_SRC

or create an =Option= out of the initial assignment

#+BEGIN_SRC scala
scala> for {
         initial <- Option(getDefault)
         i <- a
       } yield initial + i
#+END_SRC

#+BEGIN_ASIDE

=val= doesn't have to assign to a single value, it can be anything
that works as a =case= in a pattern match.

#+BEGIN_SRC scala
scala> val (first, second) = ("hello", "world")
first: String = hello
second: String = world

scala> val list: List[Int] = ...
scala> val head :: tail = list
head: Int = 1
tail: List[Int] = List(2, 3)
#+END_SRC

The same is true for assignment in =for= comprehensions

#+BEGIN_SRC scala
scala> val maybe = Option(("hello", "world"))
scala> for {
         entry <- maybe
         (first, _) = entry
       } yield first
res: Some(hello)
#+END_SRC

But be careful that you don't miss any cases or you'll get a runtime
exception (a /totality/ failure).

#+BEGIN_SRC scala
scala> val a :: tail = list
caught scala.MatchError: List()
#+END_SRC
#+END_ASIDE

**** Filter

It is possible to put =if= statements after a generator to filter
values by a predicate

#+BEGIN_SRC scala
reify> for {
         i  <- a
         j  <- b
         if i > j
         k  <- c
       } yield (i + j + k)

a.flatMap {
  i => b.withFilter {
    j => i > j }.flatMap {
      j => c.map {
        k => i + j + k }}}
#+END_SRC

Older versions of scala used =filter=, but =Traversable.filter=
creates new collections for every predicate, so =withFilter= was
introduced as the more performant alternative.

We can accidentally trigger a =withFilter= by providing type
information: it's actually interpreted as a pattern match.

#+BEGIN_SRC scala
reify> for { i: Int <- a } yield i

a.withFilter {
  case i: Int => true
  case _      => false
}.map { case i: Int => i }
#+END_SRC

Like in assignment, a generator can use a pattern match on the left
hand side. But unlike assignment (which throws =MatchError= on
failure), generators are /filtered/ and will not fail at runtime.
However, there is an inefficient double application of the pattern.

**** For Each

Finally, if there is no =yield=, the compiler will use =foreach=
instead of =flatMap=, which is only useful for side-effects.

#+BEGIN_SRC scala
reify> for { i <- a ; j <- b } println(s"$i $j")

a.foreach { i => b.foreach { j => println(s"$i $j") } }
#+END_SRC

**** Summary

The full set of methods supported by =for= comprehensions do not share
a common super type; each generated snippet is independently compiled.
If there were a trait, it would roughly look like:

#+BEGIN_SRC scala
trait ForComprehensible[C[_]] {
  def map[A, B](f: A => B): C[B]
  def flatMap[A, B](f: A => C[B]): C[B]
  def withFilter[A](p: A => Boolean): C[A]
  def foreach[A](f: A => Unit): Unit
}
#+END_SRC

If the context (=C[_]=) of a =for= comprehension doesn't provide its
own =map= and =flatMap=, all is not lost. If an implicit
=scalaz.Bind[T]= is available for =T=, it will provide =map= and
=flatMap=.

#+BEGIN_ASIDE

It often surprises developers when inline =Future= calculations in a
=for= comprehension do not run in parallel:

#+BEGIN_SRC scala
import scala.concurrent._
import ExecutionContext.Implicits.global

for {
  i <- Future { expensiveCalc() }
  j <- Future { anotherExpensiveCalc() }
} yield (i + j)
#+END_SRC

This is because the =flatMap= spawning =anotherExpensiveCalc= is
strictly *after* =expensiveCalc=. To ensure that two =Future=
calculations begin in parallel, start them outside the =for=
comprehension.

#+BEGIN_SRC scala
val a = Future { expensiveCalc() }
val b = Future { anotherExpensiveCalc() }
for { i <- a ; j <- b } yield (i + j)
#+END_SRC

=for= comprehensions are fundamentally for defining sequential
programs. We will show a far superior way of defining parallel
computations in a later chapter.
#+END_ASIDE

*** Unhappy path

So far we've only looked at the rewrite rules, not what is happening
in =map= and =flatMap=. Let's consider what happens when the =for=
context decides that it can't proceed any further.

In the =Option= example, the =yield= is only called when =i,j,k= are
all defined.

#+BEGIN_SRC scala
for {
  i <- a
  j <- b
  k <- c
} yield (i + j + k)
#+END_SRC

If any of =a,b,c= are =None=, the comprehension short-circuits with
=None= but it doesn't tell us what went wrong.

#+BEGIN_ASIDE

How often have you seen a function that takes =Option= parameters but
requires them all to exist? An alternative to throwing a runtime
exception is to use a =for= comprehension, giving us totality (a
return value for every input):

#+BEGIN_SRC scala
def namedThings(
  someName  : Option[String],
  someNumber: Option[Int]
): Option[String] = for {
  name   <- someName
  number <- someNumber
} yield s"$number ${name}s"
#+END_SRC

but this is verbose, clunky and bad style. If a function requires
every input then it should make its requirement explicit, pushing the
responsibility of dealing with optional parameters to its caller ---
don't use =for= unless you need to.

#+BEGIN_SRC scala
def namedThings(name: String, num: Int) = s"$num ${name}s"
#+END_SRC
#+END_ASIDE

If we use =Either=, then a =Left= will cause the =for= comprehension
to short circuit with extra information, much better than =Option= for
error reporting:

#+BEGIN_SRC scala
scala> val a = Right(1)
scala> val b = Right(2)
scala> val c: Either[String, Int] = Left("sorry, no c")
scala> for { i <- a ; j <- b ; k <- c } yield (i + j + k)

Left(sorry, no c)
#+END_SRC

And lastly, let's see what happens with a =Future= that fails:

#+BEGIN_SRC scala
scala> import scala.concurrent._
scala> import ExecutionContext.Implicits.global
scala> for {
         i <- Future.failed[Int](new Throwable)
         j <- Future { println("hello") ; 1 }
       } yield (i + j)
scala> Await.result(f, duration.Duration.Inf)
caught java.lang.Throwable
#+END_SRC

The =Future= that prints to the terminal is never called because, like
=Option= and =Either=, the =for= comprehension short circuits.

Short circuiting for the unhappy path is a common and important theme.
=for= comprehensions cannot express resource cleanup: there is no way
to =try= / =finally=. This is good, in FP it puts a clear ownership of
responsibility for unexpected error recovery and resource cleanup onto
the context (which is usually a =Monad= as we'll see later), not the
business logic.

*** Gymnastics

Although it's easy to rewrite simple sequential code as a =for=
comprehension, sometimes we'll want to do something that appears to
require mental summersaults. This section collects some practical
examples and how to deal with them.

**** Fallback Logic

Let's say we are calling out to a method that returns an =Option= and
if it's not successful we want to fallback to another method (and so
on and so on), like when we're using a cache:

#+BEGIN_SRC scala
def getFromRedis(s: String): Option[String]
def getFromSql(s: String): Option[String]

getFromRedis(key) orElse getFromSql(key)
#+END_SRC

If we have to do this for an asynchronous version of the same API

#+BEGIN_SRC scala
def getFromRedis(s: String): Future[Option[String]]
def getFromSql(s: String): Future[Option[String]]
#+END_SRC

then we have to be careful not to do extra work because

#+BEGIN_SRC scala
for {
  cache <- getFromRedis(key)
  sql   <- getFromSql(key)
} yield cache orElse sql
#+END_SRC

will run both queries. We can pattern match on the first result but
the type is wrong

#+BEGIN_SRC scala
for {
  cache <- getFromRedis(key)
  res   <- cache match {
             case Some(_) => cache !!! wrong type !!!
             case None    => getFromSql(key)
           }
} yield res
#+END_SRC

We need to create a =Future= from the =cache=

#+BEGIN_SRC scala
for {
  cache <- getFromRedis(key)
  res   <- cache match {
             case Some(_) => Future.successful(cache)
             case None    => getFromSql(key)
           }
} yield res
#+END_SRC

=Future.successful= creates a new =Future=, much like an =Option= or
=List= constructor.

If functional programming was like this all the time, it'd be a
nightmare. Thankfully these tricky situations are the corner cases.

**** Early Exit

Let's say we have some condition that should exit early.

If we want to exit early as an error we can use the context's
shortcut, e.g. synchronous code that throws an exception

#+BEGIN_SRC scala
  def getA: Int = ...

  val a = getA
  require(a > 0, s"$a must be positive")
  a * 10
#+END_SRC

can be rewritten as async

#+BEGIN_SRC scala
  def getA: Future[Int] = ...
  def error(msg: String): Future[Nothing] =
    Future.failed(new RuntimeException(msg))

  for {
    a <- getA
    b <- if (a <= 0) error(s"$a must be positive")
         else Future.successful(a)
  } yield b * 10
#+END_SRC

But if we want to exit early with a successful return value, we have
to use a nested =for= comprehension, e.g.

#+BEGIN_SRC scala
  def getA: Int = ...
  def getB: Int = ...

  val a = getA
  if (a <= 0) 0
  else a * getB
#+END_SRC

is rewritten asynchronously as

#+BEGIN_SRC scala
  def getA: Future[Int] = ...
  def getB: Future[Int] = ...

  for {
    a <- getA
    c <- if (a <= 0) Future.successful(0)
         else for { b <- getB } yield a * b
  } yield c
#+END_SRC

#+BEGIN_ASIDE

If there is an implicit =Monad[T]= for =T[_]= (i.e. =T= is monadic)
then scalaz lets us create a =T[A]= from a value =a:A= by calling
=a.pure[T]=.

Scalaz provides =Monad[Future]= and =.pure[Future]= simply calls
=Future.successful=. Besides =pure= being slightly shorter to type, it
is a general concept that works beyond =Future=, and is therefore
recommended.

#+BEGIN_SRC scala
  for {
    a <- getA
    c <- if (a <= 0) 0.pure[Future]
         else for { b <- getB } yield a * b
  } yield c
#+END_SRC
#+END_ASIDE

*** Incomprehensible

The context we're comprehending over must stay the same: we can't mix
contexts.

#+BEGIN_SRC scala
scala> def option: Option[Int] = ...
scala> def future: Future[Int] = ...
scala> for {
         a <- option
         b <- future
       } yield a * b
<console>:23: error: type mismatch;
 found   : Future[Int]
 required: Option[?]
         b <- future
              ^
#+END_SRC

Nothing can help us mix arbitrary contexts in a =for= comprehension
because the meaning is not well defined.

But when we have nested contexts the intention is usually obvious yet
the compiler still doesn't accept our code.

#+BEGIN_SRC scala
scala> def getA: Future[Option[Int]] = ...
scala> def getB: Future[Option[Int]] = ...
scala> for {
         a <- getA
         b <- getB
       } yield a * b
<console>:30: error: value * is not a member of Option[Int]
       } yield a * b
                 ^
#+END_SRC

Here we want =for= to take care of the outer context and let us write
our code on the inner =Option=. Hiding the outer context is exactly
what a /monad transformer/ does, and scalaz provides implementations
for =Option= and =Either= named =OptionT= and =EitherT= respectively.

The outer context can be anything that normally works in a =for=
comprehension, but it needs to stay the same throughout.

We create an =OptionT= from each method call. This changes the context
of the =for= from =Future[Option[_]]= to =OptionT[Future, _]=.

#+BEGIN_SRC scala
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
       } yield a * b
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

=.run= returns us to the original context

#+BEGIN_SRC scala
scala> result.run
res: Future[Option[Int]] = Future(<not completed>)
#+END_SRC

Alternatively, =OptionT[Future, Int]= has =getOrElse= and =getOrElseF=
methods, taking =Int= and =Future[Int]= respectively, returning a
=Future[Int]=.

The monad transformer also allows us to mix =Future[Option[_]]= calls
with methods that just return plain =Future= via =.liftM[OptionT]=
(provided by scalaz when an implicit =Monad= is available):

#+BEGIN_SRC scala
scala> def getC: Future[Int] = ...
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
         c <- getC.liftM[OptionT]
       } yield a * b / c
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

and we can mix with methods that return plain =Option= by wrapping
them in =Future.successful= (=.pure[Future]=) followed by =OptionT=

#+BEGIN_SRC scala
scala> def getD: Option[Int] = ...
scala> val result = for {
         a <- OptionT(getA)
         b <- OptionT(getB)
         c <- getC.liftM[OptionT]
         d <- OptionT(getD.pure[Future])
       } yield (a * b) / (c * d)
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

It is messy again, but it's better than writing nested =flatMap= and
=map= by hand. We can clean it up with a DSL that handles all the
required conversions into =OptionT[Future, _]=

#+BEGIN_SRC scala
def liftFutureOption[A](f: Future[Option[A]]) = OptionT(f)
def liftFuture[A](f: Future[A]) = f.liftM[OptionT]
def liftOption[A](o: Option[A]) = OptionT(o.pure[Future])
def lift[A](a: A)               = liftOption(Some(a))
#+END_SRC

combined with the /thrush operator/ =|>=, which applies the function
on the right to the value on the left, to visually separate the logic
from the transformers

#+BEGIN_SRC scala
scala> val result = for {
         a <- getA       |> liftFutureOption
         b <- getB       |> liftFutureOption
         c <- getC       |> liftFuture
         d <- getD       |> liftOption
         e <- 10         |> lift
       } yield e * (a * b) / (c * d)
result: OptionT[Future, Int] = OptionT(Future(<not completed>))
#+END_SRC

This approach also works for =EitherT= (and others) as the inner
context, but their lifting methods are more complex and require
parameters. Scalaz provides monad transformers for a lot of its own
types, so it's worth checking if one is available.

Implementing a monad transformer is an advanced topic. Although
=ListT= exists, it should be avoided because it can unintentionally
reorder =flatMap= calls according to
https://github.com/scalaz/scalaz/issues/921. A better alternative is
=StreamT=, which we will visit later.

** Application Design

In this chapter we will write the business logic and tests for a
purely functional server application.

*** Specification

Our application will manage a just-in-time build farm on a shoestring
budget. It will listen to a [[https://github.com/drone/drone][Drone]] Continuous Integration server, and
spawn worker agents using [[https://cloud.google.com/container-engine/][Google Container Engine]] (GKE) to meet the
demand of the work queue.

#+BEGIN_SRC dot :cmd circo :file images/architecture.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Palatino, shape=box];
    
    Agents [shape=doubleoctagon]
    Google
    Drone
    App [shape=trapezium]
    Github

    Google -> Agents

    Github -> Drone
    App -> Drone [label = "backlog\nagents"]
    App -> Google [label = "start/stop\nstatus\ncurrent time"]
    Drone -> App
    Google -> App

    Agents -> Drone [label = "subscribe"]
}
#+END_SRC

#+RESULTS:
[[file:images/architecture.png]]

Drone receives work when a contributor submits a github pull request
to a managed project. Drone assigns the work to its agents, each
processing one job at a time.

The goal of our app is to ensure that there are enough agents to
complete the work, with a cap on the number of agents, whilst
minimising the total cost. Our app needs to know the number of items
in the /backlog/ and the number of available /agents/.

Google can spawn /nodes/, each can host multiple drone agents. When an
agent starts up, it registers itself with drone and drone takes care
of the lifecycle (including keep-alive calls to detect removed
agents).

GKE charges a fee per minute of uptime, rounded up to the nearest hour
for each node. One does not simply spawn a new node for each job in
the work queue, we must re-use nodes and retain them until their 59th
minute to get the most value for money.

Our app needs to be able to start and stop nodes, as well as check
their status (e.g. uptimes, list of inactive nodes) and to know what
time GKE believes it to be.

In addition, there is no API to talk directly to an /agent/ so we do
not know if any individual agent is performing any work for the drone
server. If we accidentally stop an agent whilst it is performing work,
it is inconvenient and requires a human to restart the job.

Contributors can manually add agents to the farm, so counting agents
and nodes is not equivalent. We don't need to supply any nodes if
there are agents available.

The failure mode should always be to take the least costly option.

Both Drone and GKE have a JSON over REST API with OAuth 2.0
authentication.

*** Interfaces / Algebras

Let's codify the architecture diagram from the previous section.

In FP, an /algebra/ takes the place of an =interface= in Java, or the
set of valid messages for an =Actor= in Akka. This is the layer where
we define all side-effecting interactions of our system.

There is tight iteration between writing the business logic and the
algebra: it is a good level of abstraction to design a system.

#+BEGIN_SRC scala
package algebra

import java.time.ZonedDateTime
import scalaz.NonEmptyList

trait Drone[F[_]] {
  def getBacklog: F[Int]
  def getAgents: F[Int]
}

final case class MachineNode(id: String)
trait Machines[F[_]] {
  def getTime: F[ZonedDateTime]
  def getManaged: F[NonEmptyList[MachineNode]]
  def getAlive: F[Map[MachineNode, ZonedDateTime]] // with start zdt
  def start(node: MachineNode): F[MachineNode]
  def stop(node: MachineNode): F[MachineNode]
}
#+END_SRC

We've used =NonEmptyList=, easily created by calling =.toNel= on the
stdlib's =List= (returning an =Option[NonEmptyList]=), otherwise
everything should be familiar.

#+BEGIN_ASIDE
It is good practice in FP to encode constraints in parameters *and*
return types --- it means we never need to handle situations that are
impossible. However, this often conflicts with the /Effective Java/
wisdom of unconstrained parameters and specific return types.

Although we agree that parameters should be as general as possible, we
do not agree that a function should take =Seq= unless it can handle
empty =Seq=, otherwise the only course of action would be to
exception, breaking totality and causing a side effect. We prefer
=NonEmptyList=, not because it is a =List=, but because of its
non-empty property.
#+END_ASIDE

*** Business Logic

Now we write the business logic that defines the application's
behaviour, considering only the happy path.

First, the imports

#+BEGIN_SRC scala
package logic

import java.time.ZonedDateTime
import java.time.temporal.ChronoUnit

import scala.concurrent.duration._

import scalaz._
import Scalaz._

import algebra._
#+END_SRC

We need a =WorldView= class to hold a snapshot of our knowledge of the
world. If we were designing this application in Akka, =WorldView=
would probably be a =var= in a stateful =Actor=.

=WorldView= aggregates the return values of all the methods in the
algebras, and adds a /pending/ field to track unfulfilled requests.

#+BEGIN_SRC scala
final case class WorldView(
  backlog: Int,
  agents: Int,
  managed: NonEmptyList[MachineNode],
  alive: Map[MachineNode, ZonedDateTime],
  pending: Map[MachineNode, ZonedDateTime], // requested at zdt
  time: ZonedDateTime
)
#+END_SRC

Now we are ready to write our business logic, but we need to indicate
that we depend on =Drone= and =Machines=.

We create a /module/ to contain our main business logic. A module is
pure and depends only on other modules, algebras and pure functions.

#+BEGIN_SRC scala
final class DynAgents[F[_]](implicit
                            M: Monad[F],
                            d: Drone[F],
                            m: Machines[F]) {
#+END_SRC

The implicit =Monad[F]= means that =F= is /monadic/, allowing us to
use =map=, =pure= and, of course, =flatMap= via =for= comprehensions.

We have access to the algebra of =Drone= and =Machines= as =d= and
=m=, respectively. Declaring injected dependencies this way should be
familiar if you've ever used Spring's =@Autowired=.

Our business logic will run in an infinite loop (pseudocode)

#+BEGIN_SRC python
state = initial()
while True:
  state = update(state)
  state = act(state)
#+END_SRC

We must write three functions: =initial=, =update= and =act=, all
returning an =F[WorldView]=.

**** initial

In =initial= we call all external services and aggregate their results
into a =WorldView=. We default the =pending= field to an empty =Map=.

#+BEGIN_SRC scala
  def initial: F[WorldView] = for {
    db <- d.getBacklog
    da <- d.getAgents
    mm <- m.getManaged
    ma <- m.getAlive
    mt <- m.getTime
  } yield WorldView(db, da, mm, ma, Map.empty, mt)
#+END_SRC

Recall from Chapter 1 that =flatMap= (i.e. when we use the =<-=
generator) allows us to operate on a value that is computed at
runtime. When we return an =F[_]= we are returning another program to
be interpreted at runtime, that we can then =flatMap=. This is how we
safely chain together sequential side-effecting code, whilst being
able to provide a pure implementation for tests. FP could be described
as Extreme Mocking.

**** update

=update= should call =initial= to refresh our world view, preserving
known =pending= actions.

If a node has changed state, we remove it from =pending= and if a
pending action is taking longer than 10 minutes to do anything, we
assume that it failed and forget that we asked to do it.

#+BEGIN_SRC scala
  def update(old: WorldView): F[WorldView] = for {
    snap <- initial
    changed = symdiff(old.alive.keySet, snap.alive.keySet)
    pending = (old.pending -- changed).filterNot {
      case (_, started) => timediff(started, snap.time) >= 10.minutes
    }
    update = snap.copy(pending = pending)
  } yield update

  private def symdiff[T](a: Set[T], b: Set[T]): Set[T] =
    (a union b) -- (a intersect b)

  private def timediff(from: ZonedDateTime, to: ZonedDateTime): FiniteDuration =
    ChronoUnit.MINUTES.between(from, to).minutes
#+END_SRC

Note that we use assignment for pure functions like =symdiff=,
=timediff= and =copy=. Pure functions don't need test mocks, they have
explicit inputs and outputs, so you could move all pure code into
standalone methods on a stateless =object=, testable in isolation.
We're happy testing only the public methods, preferring that our
business logic is easy to read.

**** act

The =act= method is slightly more complex, so we'll split it into two
parts for clarity: detection of when an action needs to be taken,
followed by taking action. This simplification means that we can only
perform one action per invocation, but that is reasonable because we
can control the invocations and may choose to re-run =act= until no
further action is taken.

We write the scenario detectors as extractors for =WorldView=, which
is nothing more than an expressive way of writing =if= / =else=
conditions.

We need to add agents to the farm if there is a backlog of work, we
have no agents, we have no nodes alive, and there are no pending
actions. We return a candidate node that we would like to start:

#+BEGIN_SRC scala
  private object NeedsAgent {
    def unapply(world: WorldView): Option[MachineNode] = world match {
      case WorldView(backlog, 0, managed, alive, pending, _)
           if backlog > 0 && alive.isEmpty && pending.isEmpty
             => Option(managed.head)
      case _ => None
    }
  }
#+END_SRC

If there is no backlog, we should stop all nodes that have become
stale (they are not doing any work). However, since Google charge per
hour we only shut down machines in their 58th+ minute to get the most
out of our money. We return the non-empty list of nodes to stop.

As a financial safety net, all nodes should have a maximum lifetime of
5 hours.

#+BEGIN_SRC scala
  private object Stale {
    def unapply(world: WorldView): Option[NonEmptyList[MachineNode]] =
      world match {
        case WorldView(backlog, _, _, alive, pending, time) if alive.nonEmpty =>
          (alive -- pending.keys).collect {
            case (n, started)
                if backlog == 0 && timediff(started, time).toMinutes % 60 >= 58 =>
              n
            case (n, started) if timediff(started, time) >= 5.hours => n
          }.toList.toNel

        case _ => None
      }
  }
#+END_SRC

Now that we have detected the scenarios that can occur, we can write
the =act= method. When we schedule a node to be started or stopped, we
add it to =pending= noting the time that we scheduled the action.

#+BEGIN_SRC scala
  def act(world: WorldView): F[WorldView] = world match {
    case NeedsAgent(node) =>
      for {
        _ <- m.start(node)
        update = world.copy(pending = Map(node -> world.time))
      } yield update

    case Stale(nodes) =>
      nodes.foldLeftM(world) { (world, n) =>
        for {
          _ <- m.stop(n)
          update = world.copy(pending = world.pending + (n -> world.time))
        } yield update
      }

    case _ => world.pure[F]
  }
#+END_SRC

Because =NeedsAgent= and =Stale= do not cover all possible situations,
we need a catch-all =case _= to do nothing. Recall from Chapter 2 that
=.pure= creates the =for='s (monadic) context from a value.

=foldLeftM= is like =foldLeft= over =nodes=, but each iteration of the
fold may return a monadic value. In our case, each iteration of the
fold returns =F[WorldView]=.

The =M= is for Monadic and you will find more of these /lifted/
methods that behave as one would expect, taking monadic values in
place of values.

*** Unit Tests

The FP approach to writing applications is a designer's dream: you can
delegate writing the implementations of algebras to your team members
while focusing on making your business logic meet the requirements.

Our application is highly dependent on timing and third party
webservices. If this was a traditional OOP application, we'd create
mocks for all the method calls, or test actors for the outgoing
mailboxes. FP mocking is equivalent to providing an alternative
implementation of dependency algebras. The algebras already isolate
the parts of the system that need to be mocked --- everything else is
pure.

We'll start with some test data

#+BEGIN_SRC scala
object Data {
  val node1   = MachineNode("1243d1af-828f-4ba3-9fc0-a19d86852b5a")
  val node2   = MachineNode("550c4943-229e-47b0-b6be-3d686c5f013f")
  val managed = NonEmptyList(node1, node2)

  import ZonedDateTime.parse
  val time1 = parse("2017-03-03T18:07:00.000+01:00[Europe/London]")
  val time2 = parse("2017-03-03T18:59:00.000+01:00[Europe/London]") // +52 mins
  val time3 = parse("2017-03-03T19:06:00.000+01:00[Europe/London]") // +59 mins
  val time4 = parse("2017-03-03T23:07:00.000+01:00[Europe/London]") // +5 hours

  val needsAgents = WorldView(5, 0, managed, Map.empty, Map.empty, time1)
}
import Data._
#+END_SRC

We implement algebras by creating /handlers/ that extend =Drone= and
=Machines= with a specific monadic context, =Id= being the simplest.

Our "mock" implementations simply play back a fixed =WorldView=. We've
isolated the state of our system, so we can use =var= to store the
state (but this is not threadsafe).

#+BEGIN_SRC scala
class StaticHandlers(state: WorldView) {
  var started, stopped: Int = 0

  implicit val drone: Drone[Id] = new Drone[Id] {
    def getBacklog: Int = state.backlog
    def getAgents: Int = state.agents
  }

  implicit val machines: Machines[Id] = new Machines[Id] {
    def getAlive: Map[MachineNode, ZonedDateTime] = state.alive
    def getManaged: NonEmptyList[MachineNode] = state.managed
    def getTime: ZonedDateTime = state.time
    def start(node: MachineNode): MachineNode = { started += 1 ; node }
    def stop(node: MachineNode): MachineNode = { stopped += 1 ; node }
  }

  val program = DynAgents[Id]
}
#+END_SRC

When we write a unit test (here using =FlatSpec= from scalatest), we
create an instance of =StaticHandlers= and then import all of its
members.

Our implicit =drone= and =machines= both use the =Id= execution
context and therefore interpreting this program with them returns an
=Id[WorldView]= that we can assert on.

In this trivial case we just check that the =initial= method returns
the same value that we use in the static handlers:

#+BEGIN_SRC scala
  "Business Logic" should "generate an initial world view" in {
    val handlers = new StaticHandlers(needsAgents)
    import handlers._

    program.initial shouldBe needsAgents
  }
#+END_SRC

We can create more advanced tests of the =update= and =act= methods,
helping us flush out bugs and refine the requirements:

#+BEGIN_SRC scala
  it should "remove changed nodes from pending" in {
    val world = WorldView(0, 0, managed, Map(node1 -> time3), Map.empty, time3)
    val handlers = new StaticHandlers(world)
    import handlers._

    val old = world.copy(alive = Map.empty,
                         pending = Map(node1 -> time2),
                         time = time2)
    program.update(old) shouldBe world
  }

  it should "request agents when needed" in {
    val handlers = new StaticHandlers(needsAgents)
    import handlers._

    val expected = needsAgents.copy(
      pending = Map(node1 -> time1)
    )

    program.act(needsAgents) shouldBe expected

    handlers.stopped shouldBe 0
    handlers.started shouldBe 1
  }
#+END_SRC

It would be boring to go through the full test suite. Convince
yourself with a thought experiment that the following tests are easy
to implement using the same approach:

- not request agents when pending
- don't shut down agents if nodes are too young
- shut down agents when there is no backlog and nodes will shortly incur new costs
- not shut down agents if there are pending actions
- shut down agents when there is no backlog if they are too old
- shut down agents, even if they are potentially doing work, if they are too old
- ignore unresponsive pending actions during update

All of these tests are synchronous and isolated to the test runner's
thread (which could be running tests in parallel). If we'd designed
our test suite in Akka, our tests would be subject to arbitrary
timeouts and failures would be hidden in logfiles.

The productivity boost of simple tests for business logic cannot be
overstated. Consider that 90% of an application developer's time
interacting with the customer is in refining, updating and fixing
these business rules. Everything else is implementation detail.

*** Parallel

The application that we have designed runs each of its algebraic
methods sequentially. But there are some obvious places where work can
be performed in parallel.

**** initial

In our definition of =initial= we could ask for all the information we
need at the same time instead of one query at a time.

As opposed to =flatMap= for sequential operations, scalaz uses
=Apply= syntax for parallel operations:

#+BEGIN_SRC scala
^^^^(d.getBacklog, d.getAgents, m.getManaged, m.getAlive, m.getTime)
#+END_SRC

which can also use infix notation:

#+BEGIN_SRC scala
(d.getBacklog |@| d.getAgents |@| m.getManaged |@| m.getAlive |@| m.getTime)
#+END_SRC

If each of the parallel operations returns a value in the same monadic
context, we can apply a function to the results when they all return.
Rewriting =update= to take advantage of this:

#+BEGIN_SRC scala
def initial: F[WorldView] =
  ^^^^(d.getBacklog, d.getAgents, m.getManaged, m.getAlive, m.getTime) {
    case (db, da, mm, ma, mt) => WorldView(db, da, mm, ma, Map.empty, mt)
  }
#+END_SRC

**** act

In the current logic for =act=, we are stopping each node
sequentially, waiting for the result, and then proceeding. But we
could stop all the nodes in parallel and then update our view of the
world.

A disadvantage of doing it this way is that any failures will cause us
to short-circuit before updating the =pending= field. But that's a
reasonable tradeoff since our =update= will gracefully handle the case
where a =node= is shut down unexpectedly.

We need a method that operates on =NonEmptyList= that allows us to
=map= each element into an =F[MachineNode]=, returning an
=F[NonEmptyList[MachineNode]]=. The method is called =traverse=, and
when we =flatMap= over it we get a =NonEmptyList[MachineNode]= that we
can deal with in a simple way:

#+BEGIN_SRC scala
      for {
        stopped <- nodes.traverse(m.stop)
        updates = stopped.map(_ -> world.time).toList.toMap
        update = world.copy(pending = world.pending ++ updates)
      } yield update
#+END_SRC

Arguably, this is easier to understand than the sequential version.

**** Parallel Interpretation

Marking something as suitable for parallel execution does not
guarantee that it will be executed in parallel: that is the
responsibility of the handler. Not to state the obvious: parallel
execution is supported by =Future=, but not =Id=.

Of course, we need to be careful when implementing handlers such that
they can perform operations safely in parallel, perhaps requiring
protecting internal state with concurrency locks or actors.

*** Summary

1. /algebras/ define the boundaries between systems, implemented by
   /handlers/.
2. /modules/ define pure logic and depend on algebras and other
   modules.
3. modules are /interpreted/ by handlers
4. Test handlers can mock out the side-effecting parts of the system
   with trivial implementations, enabling a high level of test
   coverage for the business logic.
5. algebraic methods can be performed in parallel by taking their
   product or traversing sequences (caveat emptor, revisited later).

** Data and Functionality

From OOP we are used to thinking about data and functionality
together: class hierarchies carry methods, and traits can demand that
data fields exist. Runtime polymorphism of an object is in terms of
"is a" relationships, requiring classes to inherit from common
interfaces. This can get messy as a codebase grows. Simple data types
become obscured by hundreds of lines of methods, trait mixins suffer
from initialisation order errors, and testing / mocking of highly
coupled components becomes a chore.

FP takes a different approach, defining data and functionality
separately. In this chapter, we will cover the basics of data types
and the advantages of constraining ourselves to a subset of the Scala
language. We will also discover /typeclasses/ as a way to achieve
compiletime polymorphism: thinking about functionality of a data
structure in terms of "has a" rather than "is a" relationships.

*** Data

In FP we make data types explicit, rather than hidden as
implementation detail.

The fundamental building blocks of data types are

- =final case class= also known as /products/
- =sealed abstract class= also known as /coproducts/
- =case object= and =Int=, =Double=, =String= (etc) /values/ 

with no methods or fields other than the constructor parameters.

The collective name for /products/, /coproducts/ and /values/ is
/Algebraic Data Type/ (ADT).

We compose data types from the =AND= and =XOR= (exclusive =OR=)
Boolean algebra: a product contains every type that it is composed of,
but a coproduct can be only one. For example

- product: =ABC = a AND b AND c=
- coproduct: =XYZ = x XOR y XOR z=

written in Scala

#+BEGIN_SRC scala
// values
case object A
type B = String
type C = Int

// product
final case class ABC(a: A.type, b: B, c: C)

// coproduct
sealed abstract class XYZ
case object X extends XYZ
case object Y extends XYZ
final case class Z(b: B) extends XYZ
#+END_SRC

**** Generalised ADTs

When we introduce a type parameter into an ADT, we call it a
/Generalised Algebraic Data Type/ (GADT).

=scalaz.IList=, a safe invariant alternative to the stdlib =List=, is
a GADT:

#+BEGIN_SRC scala
sealed abstract class IList[A]
case object INil extends IList[Nothing]
final case class ICons[A](head: A, tail: IList[A]) extends IList[A]
#+END_SRC

If an ADT refers to itself, we call it a /recursive type/. =IList= is
recursive because =ICons= contains a reference to =IList=.

**** Functions on ADTs

ADTs can contain /pure functions/

#+BEGIN_SRC scala
final case class UserConfiguration(accepts: Int => Boolean)
#+END_SRC

But ADTs that contain functions come with some caveats as they don't
translate perfectly onto the JVM. For example, legacy =Serializable=,
=hashCode=, =equals= and =toString= do not behave as one might
reasonably expect.

Unfortunately, =Serializable= is used by popular frameworks, despite
far superior alternatives. A common pitfall is forgetting that
=Serializable= may attempt to serialise the entire closure of a
function, which can crash production servers. A similar caveat applies
to legacy Java classes such as =Throwable=, which can carry references
to arbitrary objects. This is one of the reasons why we restrict what
can live on an ADT.

A similar caveat applies to /by name/, known as /lazy/ parameters

#+BEGIN_SRC scala
final case class UserConfiguration(vip: => Boolean)
#+END_SRC

which are equivalent to functions that take no parameter.

We will explore alternatives to the legacy methods when we discuss the
scalaz library in the next chapter, at the cost of losing
interoperability with some legacy Java and Scala code.

**** Exhaustivity

It is important that we use =sealed abstract class=, not just
=abstract class=, when defining a data type. Sealing a =class= means
that all subtypes must be defined in the same file, allowing the
compiler to know about them in pattern match exhaustivity checks and
in macros that eliminate boilerplate. e.g.

#+BEGIN_SRC
scala> sealed abstract class Foo
       final case class Bar(flag: Boolean) extends Foo
       final case object Baz extends Foo

scala> def thing(foo: Foo) = foo match {
         case Bar(_) => true
       }
<console>:14: error: match may not be exhaustive.
It would fail on the following input: Baz
       def thing(foo: Foo) = foo match {
                             ^
#+END_SRC

This shows the developer what they have broken when they add a new
product to the codebase. We're using =-Xfatal-warnings=, otherwise
this is just a warning.

However, the compiler will not perform exhaustivity checking if the
=class= is not sealed or if there are guards, e.g.

#+BEGIN_SRC
scala> def thing(foo: Foo) = foo match {
         case Bar(flag) if flag => true
       }

scala> thing(Baz)
scala.MatchError: Baz (of class Baz$)
  at .thing(<console>:15)
#+END_SRC

To remain safe, [[https://github.com/wartremover/wartremover/issues/382][don't use guards on =sealed= types]].

The [[https://github.com/scala/scala/pull/5617][=-Xstrict-patmat-analysis=]] flag has been proposed as a language
improvement to perform additional pattern matcher checks.

**** Alternative Products and Coproducts

Another form of product is a tuple, which is like an unlabelled =final
case class=.

=(A.type, B, C)= is equivalent to =ABC= in the above example but it is
best to use =final case class= when part of an ADT because the lack of
names is awkward to deal with.

Another form of coproduct is when we nest =Either= types. e.g.

#+BEGIN_SRC scala
Either[X.type, Either[Y.type, Z]]
#+END_SRC

equivalent to the =XYZ= sealed abstract class. A cleaner syntax to define
nested =Either= types is to create an alias type ending with a colon,
allowing infix notation with association from the right:

#+BEGIN_SRC scala
type |:[L,R] = Either[L, R]

X.type |: Y.type |: Z
#+END_SRC

This is useful to create anonymous coproducts when you can't put all
the implementations into the same source file.

#+BEGIN_SRC scala
type Accepted = String |: Long |: Boolean
#+END_SRC

Yet another alternative coproduct is to create a custom =sealed abstract class=
with =final case class= definitions that simply wrap the desired type:

#+BEGIN_SRC scala
sealed abstract class Accepted
final case class AcceptedString(value: String) extends Accepted
final case class AcceptedLong(value: Long) extends Accepted
final case class AcceptedBoolean(value: Boolean) extends Accepted
#+END_SRC

Pattern matching on these forms of coproduct can be tedious, which is
why [[https://contributors.scala-lang.org/t/733][Union Types]] are being explored in the Dotty next-generation scala
compiler. Workarounds such as [[https://github.com/propensive/totalitarian][totalitarian]]'s =Disjunct= exist as
another way of encoding anonymous coproducts and [[https://github.com/fommil/stalagmite/issues/37][stalagmite]] aims to
reduce the boilerplate for the approaches presented here.

#+BEGIN_ASIDE
We can also use a =sealed trait= in place of a =sealed abstract class=
but there are binary compatibility advantages to using =abstract
class=. A =sealed trait= is only needed if you need to create a
complicated ADT with multiple inheritance.
#+END_ASIDE

**** Convey Information

Besides being a container for necessary business information, data
types can be used to encode constraints. For example,

#+BEGIN_SRC scala
final case class NonEmptyList[A](head: A, tail: IList[A])
#+END_SRC

can never be empty. This makes =scalaz.NonEmptyList= a useful data
type despite containing the same information as =List=.

In addition, wrapping an ADT can convey information such as if it
contains valid instances. Instead of breaking /totality/ by throwing
an exception

#+BEGIN_SRC scala
final case class Person(name: String, age: Int) {
  require(name.nonEmpty && age > 0) // breaks totality, don't do this
}
#+END_SRC

we can use the =Either= data type to provide =Right[Person]= instances
and protect invalid instances from propagating:

#+BEGIN_SRC scala
final case class Person private(name: String, age: Int)
object Person {
  def apply(name: String, age: Int): Either[String, Person] = {
    if (name.nonEmpty && age > 0) Right(new Person(name, age))
    else Left(s"bad input: $name, $age")
  }
}

def welcome(person: Person): String =
  s"${person.name} you look wonderful at ${person.age}!"

for {
  person <- Person("", -1)
} yield welcome(person)
#+END_SRC

We will see a better way of reporting validation errors when we
introduce =scalaz.Validation= in the next chapter.

**** Simple to Share

By not providing any functionality, ADTs can have a minimal set of
dependencies. This makes them easy to publish and share with other
developers. By using a simple data modelling language, it makes it
possible to interact with cross-discipline teams, such as DBAs, UI
developers and business analysts, using the actual code instead of a
hand written document as the source of truth.

Furthermore, tooling can be more easily written to produce or consume
schemas from other programming languages and wire protocols.

**** Counting Complexity

The complexity of a data type is the number of instances that can
exist. A good data type has the least amount of complexity it needs to
hold the information it conveys, and no more.

Values have a built-in complexity:

- =Unit= has one instance (why it's called "unit")
- =Boolean= has two instances
- =Int= has 4,294,967,295 instances
- =String= has effectively infinite instances

To find the complexity of a product, we multiply the complexity of
each part.

- =(Boolean, Boolean)= has 4 instances (=2*2=)
- =(Boolean, Boolean, Boolean)= has 8 instances (=2*2*2=)

To find the complexity of a coproduct, we add the complexity of each
part.

- =(Boolean |: Boolean)= has 4 instances (=2+2=)
- =(Boolean |: Boolean |: Boolean)= has 6 instances (=2+2+2=)

To find the complexity of a GADT, multiply each part by the complexity
of the type parameter:

- =Option[Boolean]= has 3 instances, =Some[Boolean]= and =None= (=2+1=)

In FP, functions are /total/ and must return an instance for every
input, no =Exception=. Minimising the complexity of inputs and outputs
is the best way to achieve totality. As a rule of thumb, it is a sign
of a badly designed function when the complexity of a function's
return value is larger than the product of its inputs: it is a source
of entropy.

The complexity of a total function itself is the number of possible
functions that can satisfy the type signature: the output to the power
of the input.

- =Unit=>Boolean= has complexity 2
- =Boolean=>Boolean= has complexity 4
- =Option[Boolean]=>Option[Boolean]= has complexity 27
- =Boolean=>Int= is a mere quintillion going on a sextillion.
- =Int=>Boolean= is so big that if all implementations were assigned a
  unique number, each number would be 4GB.

In reality, =Int=>Boolean= will be something simple like =isOdd=,
=isEven= or a sparse =BitSet=. This function, when used in an ADT,
could be better replaced with a coproduct labelling the limited set of
functions that are relevant.

When your complexity is always "infinity in, infinity out" you should
consider introducing more restrictive data types and performing
validation closer to the point of input. A powerful technique to
reduce complexity is /type refinement/ which merits a dedicated
chapter later in the book. It allows the compiler to keep track of
more information than is in the bytecode, e.g. if a number is within a
specific bound.

**** Prefer Coproduct over Product

An archetypal modelling problem that comes up a lot is when there are
mutually exclusive configuration parameters =a=, =b= and =c=. The
product =(a: Boolean, b: Boolean, c: Boolean)= has complexity 8
whereas the coproduct

#+BEGIN_SRC scala
sealed abstract class Config
object Config {
  case object A extends Config
  case object B extends Config
  case object C extends Config
}
#+END_SRC

has a complexity of 3. It is better to model these configuration
parameters as a coproduct rather than allowing 5 invalid states to
exist.

The complexity of a data type also has implications on testing. It is
practically impossible to test every possible input to a function, but
it is easy to test a sample of values with the [[https://www.scalacheck.org/][scalacheck]] property. If
a random sample of a data type has a low probability of being valid,
it's a sign that the data is modelled incorrectly.

**** Optimisations

A big advantage of using a simplified subset of the Scala language to
represent data types is that tooling can optimise the JVM bytecode
representation.

For example, [[https://github.com/fommil/stalagmite][stalagmite]] aims to pack =Boolean= and =Option= fields
into an =Array[Byte]=, cache instances, memoise =hashCode=, optimise
=equals=, enforce validation, use =@switch= statements when pattern
matching, and much more. [[https://www.47deg.com/blog/iota-v0-1-0-release/][iota]] has performance improvements for nested
=Either= coproducts.

These optimisations are not applicable to OOP =class= hierarchies that
may be managing state, throwing exceptions, or providing adhoc method
implementations.

**** Generic Representation

We showed that product is synonymous with tuple and coproduct is
synonymous with nested =Either=. The [[https://github.com/milessabin/shapeless][shapeless]] library takes this
duality to the extreme and introduces a representation that is
/generic/ for all ADTs:

- =shapeless.HList= (symbolically =::=) for representing products
  (=scala.Product= already exists for another purpose)
- =shapeless.Coproduct= (symbolically =:+:=) for representing coproducts

Shapeless provides the ability to convert back and forth between a
generic representation and the ADT, allowing functions to be written
that work *for every* =final case class= and =sealed abstract class=.

#+BEGIN_SRC
scala> import shapeless._
       final case class Foo(a: String, b: Long)
       Generic[Foo].to(Foo("hello", 13L))
res: String :: Long :: HNil = hello :: 13 :: HNil

scala> Generic[Foo].from("hello" :: 13L :: HNil)
res: Foo = Foo(hello,13)

scala> sealed abstract class Bar
       case object Irish extends Bar
       case object English extends Bar

scala> Generic[Bar].to(Irish)
res: English.type :+: Irish.type :+: CNil = Inl(Irish)

scala> Generic[Bar].from(Inl(Irish))
res: Bar = Irish
#+END_SRC

=HNil= is the empty product and =CNil= is the empty coproduct.

It is not necessary to know how to write generic code to be able to
make use of shapeless. However, it is an important part of FP Scala so
we will return to it later with a dedicated chapter.

*** Functionality

Pure functions are typically defined as methods on an =object=.

#+BEGIN_SRC scala
package object math {
  def sin(x: Double): Double = java.lang.Math.sin(x)
  ...
}

math.sin(1.0)
#+END_SRC

However, it can sometimes be clunky to use =object= methods since it
reads inside-out, not left to right: it's the same problem as Java's
static methods vs class methods.

#+BEGIN_WARNING
If you like to put methods on a =trait=, requiring users to mix your
traits into their =classes= or =objects= with the /cake pattern/,
please get out of this nasty habit: you're leaking internal
implementation detail to public APIs, bloating your bytecode, and
creating a lot of noise for IDE autocompleters.
#+END_WARNING

With the =implicit class= language feature (also known as /extension
methodology/ or /syntax/), and a little boilerplate, we can get the
familiar style:

#+BEGIN_SRC scala
scala> implicit class DoubleOps(x: Double) {
         def sin: Double = math.sin(x)
       }

scala> 1.0.sin
res: Double = 0.8414709848078965
#+END_SRC

Often it's best to just skip the =object= definition and go straight
for an =implicit class=, keeping boilerplate to a minimum:

#+BEGIN_SRC scala
implicit class DoubleOps(x: Double) {
  def sin: Double = java.lang.Math.sin(x)
}
#+END_SRC

#+BEGIN_ASIDE
=implicit class= is syntax sugar for an implicit conversion:

#+BEGIN_SRC scala
implicit def DoubleOps(x: Double): DoubleOps = new DoubleOps(x)
class DoubleOps(x: Double) {
  def sin: Double = java.lang.Math.sin(x)
}
#+END_SRC

Which unfortunately has a runtime cost: each time the extension method
is called, an intermediate =DoubleOps= will be constructed and then
thrown away. This can contribute to GC pressure in hotspots.

There is a slightly more verbose form of =implicit class= that avoids
the allocation and is therefore preferred:

#+BEGIN_SRC scala
implicit final class DoubleOps(val x: Double) extends AnyVal {
  def sin: Double = java.lang.Math.sin(x)
}
#+END_SRC
#+END_ASIDE

**** Polymorphic Functions

The more common kind of function is a polymorphic function, which
lives in a /typeclass/. A typeclass is a trait that:

- holds no state
- has a type parameter
- has at least one abstract method
- may contain /generalised/ methods
- may extend other typeclasses

Typeclasses are used in the Scala stdlib. We'll explore a simplified
version of =scala.math.Numeric= to demonstrate the principle:

#+BEGIN_SRC scala
trait Ordering[T] {
  def compare(x: T, y: T): Int

  def lt(x: T, y: T): Boolean = compare(x, y) < 0
  def gt(x: T, y: T): Boolean = compare(x, y) > 0
}

trait Numeric[T] extends Ordering[T] {
  def plus(x: T, y: T): T
  def times(x: T, y: T): T
  def negate(x: T): T
  def zero: T

  def abs(x: T): T = if (lt(x, zero)) negate(x) else x
}
#+END_SRC

We can see all the key features of a typeclass in action:

- there is no state
- =Ordering= and =Numeric= have type parameter =T=
- =Ordering= has abstract =compare= and =Numeric= has abstract =plus=,
  =times=, =negate= and =zero=
- =Ordering= defines generalised =lt= and =gt= based on =compare=,
  =Numeric= defines =abs= in terms of =lt=, =negate= and =zero=.
- =Numeric= extends =Ordering=

We can now write functions for types that "have a" =Numeric=
typeclass:

#+BEGIN_SRC scala
def signOfTheTimes[T](t: T)(implicit N: Numeric[T]): T = {
  import N._
  times(negate(abs(t)), t)
}
#+END_SRC

We are no longer dependent on the OOP hierarchy of our input types,
i.e. we don't demand that our input "is a" =Numeric=, which is vitally
important if we want to support a third party class that we cannot
redefine.

Another advantage of typeclasses is that the association of
functionality to data is at compiletime, as opposed to OOP runtime
dynamic dispatch.

For example, whereas the =List= class can only have one implementation
of a method, a typeclass method allows us to have a different
implementation depending on the =List= contents and therefore offload
work to compiletime instead of leaving it to runtime.

**** Syntax

The syntax for writing =signOfTheTimes= is clunky, there are some
things we can do to clean it up.

Downstream users will prefer to see our method use /context bounds/,
since the signature reads cleanly as "takes a =T= that has a
=Numeric="

#+BEGIN_SRC scala
def signOfTheTimes[T: Numeric](t: T): T = ...
#+END_SRC

but now we have to use =implicitly[Numeric[T]]= everywhere. By
defining boilerplate on the companion of the typeclass

#+BEGIN_SRC scala
object Numeric {
  def apply[T](implicit numeric: Numeric[T]): Numeric[T] = numeric
}
#+END_SRC

we can obtain the implicit with less noise

#+BEGIN_SRC scala
def signOfTheTimes[T: Numeric](t: T): T = {
  val N = Numeric[T]
  import N._
  times(negate(abs(t)), t)
}
#+END_SRC

But it is still worse for us as the implementors. We have the
syntactic problem of inside-out static methods vs class methods. We
deal with this by introducing =ops= on the typeclass companion:

#+BEGIN_SRC scala
object Numeric {
  def apply[T](implicit numeric: Numeric[T]): Numeric[T] = numeric

  object ops {
    implicit class NumericOps[T](t: T)(implicit N: Numeric[T]) {
      def +(o: T): T = N.plus(t, o)
      def *(o: T): T = N.times(t, o)
      def unary_-: T = N.negate(t)
      def abs: T = N.abs(t)

      // duplicated from Ordering.ops
      def <(o: T): T = N.lt(t, o)
      def >(o: T): T = N.gt(t, o)
    }
  }
}
#+END_SRC

Note that =-x= is expanded into =x.unary_-= by the compiler's syntax
sugar, which is why we define =unary_-= as an extension method. We can
now write the much cleaner:

#+BEGIN_SRC scala
import Numeric.ops._
def signOfTheTimes[T: Numeric](t: T): T = -(t.abs) * t
#+END_SRC

The good news is that we never need to write this boilerplate because
[[https://github.com/mpilquist/simulacrum][Simulacrum]] provides a =@typeclass= macro annotation to have the
companion =apply= and =ops= automatically generated. It even allows us
to define alternative (usually symbolic) names for common methods. In
full:

#+BEGIN_SRC scala
import simulacrum._

@typeclass trait Ordering[T] {
  def compare(x: T, y: T): Int
  @op("<") def lt(x: T, y: T): Boolean = compare(x, y) < 0
  @op(">") def gt(x: T, y: T): Boolean = compare(x, y) > 0
}

@typeclass trait Numeric[T] extends Ordering[T] {
  @op("+") def plus(x: T, y: T): T
  @op("*") def times(x: T, y: T): T
  @op("unary_-") def negate(x: T): T
  def zero: T
  def abs(x: T): T = if (lt(x, zero)) negate(x) else x
}

import Numeric.ops._
def signOfTheTimes[T: Numeric](t: T): T = -(t.abs) * t
#+END_SRC

**** Instances

/Instances/ of =Numeric= (which are also instances of =Ordering=) are
defined as an =implicit val= that extends the typeclass, and can
provide optimised implementations for the generalised methods:

#+BEGIN_SRC scala
implicit val NumericDouble: Numeric[Double] = new Numeric[Double] {
  def plus(x: Double, y: Double): Double = x + y
  def times(x: Double, y: Double): Double = x * y
  def negate(x: Double): Double = -x
  def zero: Double = 0.0
  def compare(x: Double, y: Double): Int = java.lang.Double.compare(x, y)

  // optimised
  override def lt(x: Double, y: Double): Boolean = x < y
  override def gt(x: Double, y: Double): Boolean = x > y
  override def abs(x: Double): Double = java.lang.Math.abs(x)
}
#+END_SRC

Although we are using =+=, =*=, =unary_-=, =<= and =>= here, which are
the ops (and could be an infinite loop!), these methods exist already
on =Double=. Class methods are always used in preference to extension
methods. Indeed, the scala compiler performs special handling of
primitives and converts these method calls into raw =dadd=, =dmul=,
=dcmpl= and =dcmpg= bytecode instructions, respectively.

We can also implement =Numeric= for Java's =BigDecimal= class (avoid
=scala.BigDecimal=, [[https://github.com/scala/bug/issues/9670][it is fundamentally broken]])

#+BEGIN_SRC scala
import java.math.{ BigDecimal => BD }

implicit val NumericBD: Numeric[BD] = new Numeric[BD] {
  def plus(x: BD, y: BD): BD = x.add(y)
  def times(x: BD, y: BD): BD = x.multiply(y)
  def negate(x: BD): BD = x.negate
  def zero: BD = BD.ZERO
  def compare(x: BD, y: BD): Int = x.compareTo(y)
}
#+END_SRC

We could even take some liberties and create our own data structure
for complex numbers:

#+BEGIN_SRC scala
final case class Complex[T](r: T, i: T)
#+END_SRC

And derive a =Numeric[Complex[T]]= if =Numeric[T]= exists. Since these
instances depend on the type parameter, it is a =def=, not a =val=.

#+BEGIN_SRC scala
implicit def numericComplex[T: Numeric]: Numeric[Complex[T]] =
  new Numeric[Complex[T]] {
    type CT = Complex[T]
    def plus(x: CT, y: CT): CT = Complex(x.r + y.r, x.i + y.i)
    def times(x: CT, y: CT): CT =
      Complex(x.r * y.r + (-x.i * y.i), x.r * y.i + x.i * y.r)
    def negate(x: CT): CT = Complex(-x.r, -x.i)
    def zero: CT = Complex(Numeric[T].zero, Numeric[T].zero)
    def compare(x: CT, y: CT): Int = {
      val real = (Numeric[T].compare(x.r, y.r))
      if (real != 0) real
      else Numeric[T].compare(x.i, y.i)
    }
  }
#+END_SRC

The observant reader may notice that =abs= is not at all what a
mathematician would expect. The correct return value for =abs= should
be =T=, not =Complex[T]=.

=scala.math.Numeric= tries to do too much and does not generalise
beyond real numbers. This is a good lesson that smaller, well defined,
typeclasses are often better than a monolithic collection of overly
specific features.

If you need to write generic code that works for a wide range of
number types, prefer [[https://github.com/non/spire][spire]] to the stdlib. Indeed, in the next chapter
we will see that concepts such as having a zero element, or adding two
values, are worthy of their own typeclass.

**** Implicit Resolution

We've discussed implicits a lot: this section is to clarify what
implicits are and how they work.

/Implicit parameters/ are when a method requests that a unique
instance of a particular type is in the /implicit scope/ of the
caller, with special syntax for typeclass instances. Implicit
parameters are a clean way to thread configuration through an
application.

In this example, =foo= requires that typeclasses for =Numeric= and
shapeless' =Typeable= are available for =T=, as well as an implicit
(user-defined) =Config= object.

#+BEGIN_SRC scala
def foo[T: Numeric: Typeable](implicit conf: Config) = ...
#+END_SRC

/Implicit conversion/ is when an =implicit def= exists. One such use
of implicit conversions is to enable extension methodology. When the
compiler is resolving a call to a method, it first checks if the
method exists on the type, then its ancestors (Java-like rules). If it
fails to find a match, it will search the /implicit scope/ for
conversions to other types, then search for methods on those types.

Another use for implicit conversion is /typeclass derivation/. In the
previous section we wrote an =implicit def= that derived a
=Numeric[Complex[T]]= if a =Numeric[T]= is in the implicit scope. It
is possible to chain together many =implicit def= (including
recursively) which is the basis of /typeful programming/, allowing for
computations to be performed at compiletime rather than runtime.

The glue that combines implicit parameters (receivers) with implicit
conversion (providers) is implicit resolution.

First, the normal variable scope is searched for implicits, in order:

- local scope, including scoped imports (e.g. the block or method)
- outer scope, including scoped imports (e.g. members in the class)
- ancestors (e.g. members in the super class)
- the current package object
- ancestor package objects (only when using nested packages)
- the file's imports

If that fails to find a match, the special scope is searched, which
looks for implicit instances inside a type's companion, its package
object, outer objects (if nested), and then repeated for ancestors.
This is performed, in order, for the:

- given parameter type
- expected parameter type
- type parameter (if there is one)

If two matching implicits are found in the same phase of implicit
resolution, an /ambiguous implicit/ error is raised.

Implicits are often defined on a =trait=, which is then extended by an
object. This is to try and control the priority of an implicit
relative to another more specific one, to avoid ambiguous implicits.

The Scala Language Specification is rather vague for corner cases, and
the compiler implementation is the /de facto/ standard. There are some
rules of thumb that we will use throughout this book, e.g. prefer
=implicit val= over =implicit object= despite the temptation of less
typing. It is a [[https://github.com/scala/bug/issues/10411][quirk of implicit resolution]] that =implicit object= on
companion objects are not treated the same as =implicit val=.

Implicit resolution falls short when there is a hierarchy of
typeclasses, like =Ordering= and =Numeric=. If we write a function
that takes an implicit =Ordering=, and we call it for a type which has
an instance of =Numeric= defined on the =Numeric= companion, the
compiler will fail to find it. A workaround is to add implicit
conversions to the companion of =Ordering= that up-cast more specific
instances. [[https://github.com/lampepfl/dotty/issues/2047][Fixed In Dotty]].

# might also be fixed in scato
# https://github.com/aloiscochard/scato/issues/15

*** Modelling OAuth2

We will finish this chapter with a practical example of data modelling
and typeclass derivation, combined with algebra / module design from
the previous chapter.

In our =drone-dynamic-agents= application, we must communicate with
Drone and Google Cloud using JSON over REST. Both services use [[https://tools.ietf.org/html/rfc6749][OAuth2]]
for authentication. Although there are many ways to interpret OAuth2,
we'll focus on the version that works for Google Cloud (the Drone
version is even simpler).

**** Description

Every Google Cloud application needs to have an /OAuth 2.0 Client Key/
set up at

#+BEGIN_SRC
https://console.developers.google.com/apis/credentials?project={PROJECT_ID}
#+END_SRC

You will be provided with a /Client ID/ and a /Client secret/.

The application can then obtain a one time /code/ by making the user
perform an /Authorization Request/ in their browser (yes, really, *in
their browser*). We need to make this page open in the browser:

#+BEGIN_SRC
https://accounts.google.com/o/oauth2/v2/auth?\
  redirect_uri={CALLBACK_URI}&\
  prompt=consent&\
  response_type=code&\
  scope={SCOPE}&\
  access_type=offline&\
  client_id={CLIENT_ID}
#+END_SRC

The /code/ is delivered to the ={CALLBACK_URI}= in a =GET= request. To
capture it in our application, we need to have a web server listening
on =localhost=.

Once we have the /code/, we can perform an /Access Token Request/:

#+BEGIN_SRC
POST /oauth2/v4/token HTTP/1.1
Host: www.googleapis.com
Content-length: {CONTENT_LENGTH}
content-type: application/x-www-form-urlencoded
user-agent: google-oauth-playground
code={CODE}&\
  redirect_uri={CALLBACK_URI}&\
  client_id={CLIENT_ID}&\
  client_secret={CLIENT_SECRET}&\
  scope={SCOPE}&\
  grant_type=authorization_code
#+END_SRC

which gives a JSON response payload

#+BEGIN_SRC json
{
  "access_token": "BEARER_TOKEN",
  "token_type": "Bearer",
  "expires_in": 3600,
  "refresh_token": "REFRESH_TOKEN"
}
#+END_SRC

/Bearer tokens/ typically expire after an hour, and can be refreshed
by sending an HTTP request with any valid /refresh token/:

#+BEGIN_SRC
POST /oauth2/v4/token HTTP/1.1
Host: www.googleapis.com
Content-length: {CONTENT_LENGTH}
content-type: application/x-www-form-urlencoded
user-agent: google-oauth-playground
client_secret={CLIENT_SECRET}&
  grant_type=refresh_token&
  refresh_token={REFRESH_TOKEN}&
  client_id={CLIENT_ID}
#+END_SRC

responding with

#+BEGIN_SRC json
{
  "access_token": "BEARER_TOKEN",
  "token_type": "Bearer",
  "expires_in": 3600
}
#+END_SRC

Google expires all but the most recent 50 /bearer tokens/, so the
expiry times are just guidance. The /refresh tokens/ persist between
sessions and can be expired manually by the user. We can therefore
have a one-time setup application to obtain the refresh token and then
include the refresh token as configuration for the user's install of
the headless server.

**** Data

The first step is to model the data needed for OAuth2. We create an
ADT with fields having exactly the same name as required by the OAuth2
server. We will use =String= and =Long= for now, even though there is
a limited set of valid entries. We will remedy this when we learn
about /refined types/.

#+BEGIN_SRC scala
package http.oauth2.client.api

import spinoco.protocol.http.Uri

final case class AuthRequest(
  redirect_uri: Uri,
  scope: String,
  client_id: String,
  prompt: String = "consent",
  response_type: String = "code",
  access_type: String = "offline"
)
final case class AccessRequest(
  code: String,
  redirect_uri: Uri,
  client_id: String,
  client_secret: String,
  scope: String = "",
  grant_type: String = "authorization_code"
)
final case class AccessResponse(
  access_token: String,
  token_type: String,
  expires_in: Long,
  refresh_token: String
)
final case class RefreshRequest(
  client_secret: String,
  refresh_token: String,
  client_id: String,
  grant_type: String = "refresh_token"
)
final case class RefreshResponse(
  access_token: String,
  token_type: String,
  expires_in: Long
)
#+END_SRC

=Uri= is a typed ADT for URL requests from [[https://github.com/Spinoco/fs2-http][fs2-http]]:

#+BEGIN_WARNING
Avoid using =java.net.URL= at all costs: it uses DNS to resolve the
hostname part when performing =toString=, =equals= or =hashCode=.

Apart from being insane, and *very very* slow, these methods can throw
I/O exceptions (are not /pure/), and can change depending on your
network configuration (are not /deterministic/).

If you must use =java.net.URL= to satisfy a legacy system, at least
avoid putting it in a collection that will use =hashCode= or =equals=.
If you need to perform equality checks, create your own equality
function out of the raw =String= parts.
#+END_WARNING

**** Functionality

We need to marshal the data classes we defined in the previous section
into JSON, URLs and POST-encoded forms. Since this requires
polymorphism, we will need typeclasses.

[[https://github.com/circe/circe][circe]] gives us an ADT for JSON and typeclasses to convert to/from that
ADT (paraphrased for brevity):

#+BEGIN_SRC scala
package io.circe

import simulacrum._

sealed abstract class Json
case object JNull extends Json
final case class JBoolean(value: Boolean) extends Json
final case class JNumber(value: JsonNumber) extends Json
final case class JString(value: String) extends Json
final case class JArray(value: Vector[Json]) extends Json
final case class JObject(value: JsonObject) extends Json

@typeclass trait Encoder[T] {
  def encodeJson(t: T): Json
}
@typeclass trait Decoder[T] {
  @op("as") def decodeJson(j: Json): Either[DecodingFailure, T]
}
#+END_SRC

where =JsonNumber= and =JsonObject= are optimised specialisations of
roughly =java.math.BigDecimal= and =Map[String, Json]=. To depend on
circe in your project we must add the following to =build.sbt=:

#+BEGIN_SRC scala
val circeVersion = "0.8.0"
libraryDependencies ++= Seq(
  "io.circe"             %% "circe-core"    % circeVersion,
  "io.circe"             %% "circe-generic" % circeVersion,
  "io.circe"             %% "circe-parser"  % circeVersion
)
#+END_SRC

#+BEGIN_WARNING
=java.math.BigDecimal= and especially =java.math.BigInteger= are not
safe objects to include in wire protocol formats. It is possible to
construct valid numerical values that will exception when parsed or
hang the =Thread= forever.

Travis Brown, author of Circe, has [[https://github.com/circe/circe/blob/master/modules/core/shared/src/main/scala/io/circe/JsonNumber.scala][gone to great lengths]] to protect
us. If you want to have similarly safe numbers in your wire protocols,
either use =JsonNumber= or settle for lossy =Double=.

#+BEGIN_SRC scala
scala> new java.math.BigDecimal("1e2147483648")
java.lang.NumberFormatException
  at java.math.BigDecimal.<init>(BigDecimal.java:491)
  ... elided

scala> new java.math.BigDecimal("1e2147483647").toBigInteger
  ... hangs forever ...
#+END_SRC
#+END_WARNING

Because circe provides /generic/ instances, we can conjure up a
=Decoder[AccessResponse]= and =Decoder[RefreshResponse]=. This is an
example of parsing text into =AccessResponse=:

#+BEGIN_SRC scala
scala> import io.circe._
       import io.circe.generic.auto._

       for {
         json     <- io.circe.parser.parse("""
                     {
                       "access_token": "BEARER_TOKEN",
                       "token_type": "Bearer",
                       "expires_in": 3600,
                       "refresh_token": "REFRESH_TOKEN"
                     }
                     """)
         response <- json.as[AccessResponse]
       } yield response

res = Right(AccessResponse(BEARER_TOKEN,Bearer,3600,REFRESH_TOKEN))
#+END_SRC

We need to write our own typeclasses for URL and POST encoding. The
following is a reasonable design:

#+BEGIN_SRC scala
package http.encoding

import simulacrum._

@typeclass trait QueryEncoded[T] {
  def queryEncoded(t: T): Uri.Query
}

@typeclass trait UrlEncoded[T] {
  def urlEncoded(t: T): String
}
#+END_SRC

We need to provide typeclass instances for basic types:

#+BEGIN_SRC scala
import java.net.URLEncoder
import spinoco.protocol.http.Uri

object UrlEncoded {
  import ops._
  def instance[A](f: A => String): UrlEncoded[A] = new UrlEncoded[A] {
    override def urlEncoded(a: A): String = f(a)
  }

  implicit val UrlEncodedString: UrlEncoded[String] = instance { s =>
    URLEncoder.encode(s, "UTF-8")
  }
  implicit val UrlEncodedLong: UrlEncoded[Long] = instance { n =>
    n.toString
  }
  implicit val UrlEncodedStringySeq: UrlEncoded[Seq[(String, String)]] =
    instance { m =>
      m.map {
        case (k, v) => s"${k.urlEncoded}=${v.urlEncoded}"
      }.mkString("&")
    }
  implicit val UrlEncodedUri: UrlEncoded[Uri] = instance { u =>
    val scheme = u.scheme.toString
    val host   = u.host.host
    val port   = u.host.port.fold("")(p => s":$p")
    val path   = u.path.stringify
    val query  = u.query.params.toSeq.urlEncoded
    s"$scheme://$host$port$path?$query".urlEncoded
  }
}
#+END_SRC

#+BEGIN_ASIDE
Typing or reading

#+BEGIN_SRC scala
  implicit val UrlEncodedString: UrlEncoded[String] = new UrlEncoded[String] {
    override def urlEncoded(s: String): String = ...
  }
#+END_SRC

can be tiresome. We've basically said =UrlEncoded=, =String= four
times. A common pattern, that [[https://github.com/mpilquist/simulacrum/issues/5][may be added to simulacrum]] is to define
a method named =instance= on the typeclass companion

#+BEGIN_SRC scala
def instance[T](f: T => String): UrlEncoded[T] = new UrlEncoded[T] {
  override def urlEncoded(t: T): String = f(t)
}
#+END_SRC

which then allows for instances to be defined more tersely as

#+BEGIN_SRC scala
implicit val UrlEncodedString: UrlEncoded[String] = instance { s => ... }
#+END_SRC

Syntax sugar has been proposed in [[https://github.com/lampepfl/dotty/issues/2879][dotty]] allowing for:

#+BEGIN_SRC scala
implicit val _: UrlEncoded[String] = instance { s => ... }
#+END_SRC
#+END_ASIDE

In a dedicated chapter on /Generic Programming/ we will write generic
instances of =QueryEncoded= and =UrlEncoded=, but for now we will
write the boilerplate for the types we wish to convert:

#+BEGIN_SRC scala
  import java.net.URLDecoder
  import http.encoding._
  import UrlEncoded.ops._

  object AuthRequest {
    implicit val QueryEncoder: QueryEncoded[AuthRequest] =
      new QueryEncoded[AuthRequest] {
        private def stringify[T: UrlEncoded](t: T) =
          URLDecoder.decode(t.urlEncoded, "UTF-8")

        def queryEncoded(a: AuthRequest): Uri.Query =
          Uri.Query.empty :+
            ("redirect_uri"  -> stringify(a.redirect_uri)) :+
            ("scope"         -> stringify(a.scope)) :+
            ("client_id"     -> stringify(a.client_id)) :+
            ("prompt"        -> stringify(a.prompt)) :+
            ("response_type" -> stringify(a.response_type)) :+
            ("access_type"   -> stringify(a.access_type))
      }
  }
  object AccessRequest {
    implicit val UrlEncoder: UrlEncoded[AccessRequest] =
      new UrlEncoded[AccessRequest] {
        def urlEncoded(a: AccessRequest): String =
          Seq(
            "code"          -> a.code.urlEncoded,
            "redirect_uri"  -> a.redirect_uri.urlEncoded,
            "client_id"     -> a.client_id.urlEncoded,
            "client_secret" -> a.client_secret.urlEncoded,
            "scope"         -> a.scope.urlEncoded,
            "grant_type"    -> a.grant_type.urlEncoded
          ).urlEncoded
      }
  }
  object RefreshRequest {
    implicit val UrlEncoder: UrlEncoded[RefreshRequest] =
      new UrlEncoded[RefreshRequest] {
        def urlEncoded(r: RefreshRequest): String =
          Seq(
            "client_secret" -> r.client_secret.urlEncoded,
            "refresh_token" -> r.refresh_token.urlEncoded,
            "client_id"     -> r.client_id.urlEncoded,
            "grant_type"    -> r.grant_type.urlEncoded
          ).urlEncoded
      }
  }
#+END_SRC

**** Module

That concludes the data and functionality modelling required to
implement OAuth2. Recall from the previous chapter that we define
mockable components that need to interact with the world as algebras,
and we define pure business logic in a module.

We define our dependency algebras, and use context bounds to show that
our responses must have a =Decoder= and our =POST= payload must have a
=UrlEncoded=:

#+BEGIN_SRC scala
import java.time.LocalDateTime

package http.client.algebra {
  final case class Response[T](header: HttpResponseHeader, body: T)

  trait JsonHttpClient[F[_]] {
    def get[B: Decoder](
      uri: Uri,
      headers: List[HttpHeader] = Nil
    ): F[Response[B]]

    def postUrlencoded[A: UrlEncoded, B: Decoder](
      uri: Uri,
      payload: A,
      headers: List[HttpHeader] = Nil
    ): F[Response[B]]
  }
}

package http.oauth2.client.algebra {
  final case class CodeToken(token: String, redirect_uri: Uri)

  trait UserInteraction[F[_]] {
    /** returns the Uri of the local server */
    def start: F[Uri]

    /** prompts the user to open this Uri */
    def open(uri: Uri): F[Unit]

    /** recover the code from the callback */
    def stop: F[CodeToken]
  }

  trait LocalClock[F[_]] {
    def now: F[LocalDateTime]
  }
}
#+END_SRC

some convenient data classes

#+BEGIN_SRC scala
final case class ServerConfig(
  auth: Uri,
  access: Uri,
  refresh: Uri,
  scope: String,
  clientId: String,
  clientSecret: String
)
final case class RefreshToken(token: String)
final case class BearerToken(token: String, expires: LocalDateTime)
#+END_SRC

and then write an OAuth2 client:

#+BEGIN_SRC scala
package logic {
  import java.time.temporal.ChronoUnit
  import io.circe.generic.auto._
  import http.encoding.QueryEncoded.ops._

  class OAuth2Client[F[_]: Monad](
    config: ServerConfig
  )(
    implicit
    user: UserInteraction[F],
    server: JsonHttpClient[F],
    clock: LocalClock[F]
  ) { 
    def authenticate: F[CodeToken] =
      for {
        callback <- user.start
        params   = AuthRequest(callback, config.scope, config.clientId)
        _        <- user.open(config.auth.withQuery(params.queryEncoded))
        code     <- user.stop
      } yield code

    def access(code: CodeToken): F[(RefreshToken, BearerToken)] =
      for {
        request <- AccessRequest(code.token,
                                 code.redirect_uri,
                                 config.clientId,
                                 config.clientSecret).pure[F]
        response <- server
                     .postUrlencoded[AccessRequest, AccessResponse](
                       config.access,
                       request
                     )
        time    <- clock.now
        msg     = response.body
        expires = time.plus(msg.expires_in, ChronoUnit.SECONDS)
        refresh = RefreshToken(msg.refresh_token)
        bearer  = BearerToken(msg.access_token, expires)
      } yield (refresh, bearer)

    def bearer(refresh: RefreshToken): F[BearerToken] =
      for {
        request <- RefreshRequest(config.clientSecret,
                                  refresh.token,
                                  config.clientId).pure[F]
        response <- server
                     .postUrlencoded[RefreshRequest, RefreshResponse](
                       config.refresh,
                       request
                     )
        time    <- clock.now
        msg     = response.body
        expires = time.plus(msg.expires_in, ChronoUnit.SECONDS)
        bearer  = BearerToken(msg.access_token, expires)
      } yield bearer
  }
}
#+END_SRC

*** Summary

- data types are defined as /products/ (=final case class=) and
  /coproducts/ (=sealed abstract class= or nested =Either=).
- specific functions are defined on =object= or =implicit class=,
  according to personal taste.
- polymorphic functions are defined as /typeclasses/. Functionality is
  provided via "has a" /context bounds/, rather than "is a" class
  hierarchies.
- /typeclass instances/ are implementations of the typeclass.
- =@simulacrum.typeclass= generates =.ops= on the companion, providing
  convenient syntax for types that have a typeclass instance.
- /typeclass derivation/ is compiletime composition of typeclass
  instances.
- /generic instances/ automatically derive instances for your data
  types.

* WIP                                                                 :final:
  :PROPERTIES:
  :EXPORT_FILE_NAME: wip.md
  :END:
** Scalaz Typeclasses

In this chapter we will tour most of the typeclasses in =scalaz-core=.
We don't use everything in =drone-dynamic-agents= so we will give
standalone examples when appropriate.

There has been criticism of the naming in scalaz, and functional
programming in general. Most names follow the conventions introduced
in the Haskell programming language, based on /Category Theory/. Feel
free to set up =type= aliases in your own codebase if you would prefer
to use verbs based on the primary functionality of the typeclass (e.g.
=Mappable=, =Pureable=, =FlatMappable=) until you are comfortable with
the standard names.

Before we introduce the typeclass hierarchy, we will peek at the four
most important methods from a control flow perspective: the methods we
will use the most in typical FP applications:

| Typeclass     | Method     | From   | Given         | To        |
|---------------+------------+--------+---------------+-----------|
| =Functor=     | =map=      | =F[A]= | =(A => B)=    | =F[B]=    |
| =Applicative= | =pure=     | =A=    |               | =F[A]=    |
| =Monad=       | =flatMap=  | =F[A]= | =(A => F[B])= | =F[B]=    |
| =Traverse=    | =traverse= | =F[A]= | =(A => G[B])= | =G[F[B]]= |

We know that operations which return a =F[_]= can be run sequentially
in a =for= comprehension by =.flatMap=, defined on its =Monad[F]=. The
context =F[_]= can be thought of as a container for an intentional
/effect/ with =A= as the output: =flatMap= allows us to generate new
effects =F[B]= at runtime based on the results of evaluating previous
effects.

Of course, not all Higher Kinded Types =F[_]= are effectful, even if
they have a =Monad[F]=. Often they are data structures. By using the
least specific abstraction, we can reuse code for =List=, =Either=,
=Future= and more.

If we only need to transform the output from an =F[_]=, that's just
=map=, introduced by =Functor=. In Chapter 3, we ran effects in
parallel by creating a product and mapping over them. In Functional
Programming, parallelisable computations are considered *less*
powerful than sequential ones.

In between =Monad= and =Functor= is =Applicative=, defining =pure=
that lets us lift a value into an effect, or create a data structure
from a single value.

=traverse= is useful for rearranging Higher Kinded Types (HKTs). If
you find yourself with an =F[G[_]]= but you really need a =G[F[_]]=
then you need =Traverse=. For example, say you have a
=List[Future[Int]]= but you need it to be a =Future[List[Int]]=, just
call =.traverse(identity)=, or its simpler sibling =.sequence=.

*** Agenda

There are an overwhelming number of typeclasses, so we will cluster
them by common themes. Notably absent are typeclasses that extend
=Monad=, which get their own chapter.

Scalaz uses code generation instead of simulacrum. We'll present the
typeclasses as if simulacrum was used, but note that there are no
=ops= on the companions. All syntax is provided along with typeclasses
and data types when writing

#+BEGIN_SRC scala
import scalaz._, Scalaz._
#+END_SRC

#+BEGIN_SRC dot :file images/scalaz-core-tree.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    subgraph {
      Functor -> InvariantFunctor
      Apply -> Functor
      Applicative -> Apply
      Align -> Functor
      Bind -> Apply

      Foldable1 -> Foldable
      Traverse -> Functor
      Traverse -> Foldable
      Traverse1 -> Traverse
      Traverse1 -> Foldable1

      Monad
      "Advanced Monads" [style=dashed]
      "Advanced Monads" -> Monad

      Monad -> Applicative
      Monad -> Bind

      Contravariant -> InvariantFunctor
      Divide -> Contravariant
      Divisible -> Divide
      Cobind -> Functor
      Comonad -> Cobind

      PlusEmpty -> Plus
      IsEmpty -> PlusEmpty

      ApplicativePlus -> Applicative
      ApplicativePlus -> PlusEmpty

      ComonadStore -> Comonad

      BindRec -> Bind
    }
}
#+END_SRC

#+CAPTION: 100
#+RESULTS:
[[file:images/scalaz-core-tree.png]]

#+BEGIN_SRC dot :file images/scalaz-core-cliques.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    subgraph {
        Semigroup
        Monoid -> Semigroup
        Band -> Semigroup

        Order -> Equal
        Enum -> Order

        Bitraverse -> Bifunctor
        Bitraverse -> Bifoldable

        Category -> Compose
        Choice -> Category
        Split -> Compose
        Strong -> Profunctor
        ProChoice -> Profunctor
        Arrow -> Split
        Arrow -> Strong
        Arrow -> Category
    }
}
#+END_SRC

#+CAPTION: 100
#+RESULTS:
[[file:images/scalaz-core-cliques.png]]

#+BEGIN_SRC dot :file images/scalaz-core-loners.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    subgraph {
        Equal
        Show
        Zip
        Unzip
        Cozip
        Optional
        Compose 
        Catchable
        Associative 
        Resource
    }
}
#+END_SRC

#+CAPTION: 100
#+RESULTS:
[[file:images/scalaz-core-loners.png]]

*** Appendable Things

#+BEGIN_SRC dot :file images/scalaz-semigroup.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    Monoid -> Semigroup
    Band -> Semigroup
}
#+END_SRC

#+ATTR_LATEX: :width 5cm
#+CAPTION: 30
#+RESULTS:
[[file:images/scalaz-semigroup.png]]

#+BEGIN_SRC scala
@typeclass trait Semigroup[A] {
  @op("|+|") def append(x: A, y: => A): A

  def multiply1(value: F, n: Int): F = ...
}

@typeclass trait Monoid[A] extends Semigroup[A] {
  def zero: A

  def multiply(value: F, n: Int): F =
    if (n <= 0) zero else multiply1(value, n - 1)
}

@typeclass trait Band[A] extends Semigroup[A]
#+END_SRC

#+BEGIN_ASIDE
=|+|= is known as the TIE Fighter operator. There is an Advanced TIE
Fighter in an upcoming section, which is very exciting.
#+END_ASIDE

A =Semigroup= should exist for a type if two elements can be combined
to produce another element of the same type. The operation must be
/associative/, meaning that the order of nested operations should not
matter, i.e.

#+BEGIN_SRC scala
(a |+| b) |+| c == a |+| (b |+| c)

(1 |+| 2) |+| 3 == 1 |+| (2 |+| 3)
#+END_SRC

A =Monoid= is a =Semigroup= with a /zero/ element (also called /empty/
or /identity/). Combining =zero= with any other =a= should give =a=.

#+BEGIN_SRC scala
a |+| zero == a

a |+| 0 == a
#+END_SRC

This is probably bringing back memories of =Numeric= from Chapter 4,
which tried to do too much and was unusable beyond the most basic of
number types. There are implementations of =Monoid= for all the
primitive numbers, but the concept of /appendable/ things is useful
beyond numbers.

#+BEGIN_SRC scala
scala> "hello" |+| " " |+| "world!"
res: String = "hello world!"

scala> List(1, 2) |+| List(3, 4)
res: List[Int] = List(1, 2, 3, 4)
#+END_SRC

=Band= has the law that the =append= operation of the same two
elements is /idempotent/, i.e. gives the same value. Examples are
anything that can only be one value, such as =Unit=, least upper
bounds, or a =Set=. =Band= provides no further methods yet users can
make use of the guarantees for performance optimisation.

As a realistic example for =Monoid=, consider a trading system that
has a large database of reusable trade templates. Creating the default
values for a new trade involves selecting and combining templates with
a "last rule wins" merge policy (e.g. if templates have a value for
the same field).

We'll create a simple template schema to demonstrate the principle,
but keep in mind that a realistic system would have a more complicated
ADT.

#+BEGIN_SRC scala
sealed abstract class Currency
case object EUR extends Currency
case object USD extends Currency

final case class TradeTemplate(
  payments: List[java.time.LocalDate],
  ccy: Option[Currency],
  otc: Option[Boolean]
)
#+END_SRC

If we write a method that takes =templates: List[TradeTemplate]=, we
only need to call

#+BEGIN_SRC scala
val zero = Monoid[TradeTemplate].zero
templates.foldLeft(zero)(_ |+| _)
#+END_SRC

and our job is done!

But to get =zero= or call =|+|= we must have an instance of
=Monoid[TradeTemplate]=. Although we will generically derive this in a
later chapter, for now we'll create an instance on the companion:

#+BEGIN_SRC scala
implicit val monoid: Monoid[TradeTemplate] = Monoid.instance(
  (a, b) => TradeTemplate(a.payments |+| b.payments,
                          a.ccy |+| b.ccy,
                          a.otc |+| b.otc),
 TradeTemplate(Nil, None, None) 
)
#+END_SRC

However, this fails to compile because =Monoid[Option[T]]= defers to
=Monoid[T]= and we have neither a =Monoid[Currency]= (we did not
provide one) nor a =Monoid[Boolean]= (inclusive or exclusive logic
must be explicitly chosen).

To explain what we mean by "defers to", consider
=Monoid[Option[Int]]=:

#+BEGIN_SRC scala
scala> Option(2) |+| None
res: Option[Int] = Some(2)
scala> Option(2) |+| Option(1)
res: Option[Int] = Some(3)
#+END_SRC

We can see the content's =append= has been called, integer addition.

But our business rules state that we use "last rule wins" on
conflicts, so we introduce a higher priority implicit
=Monoid[Option[T]]= instance and use it instead of the default:

#+BEGIN_SRC scala
implicit def lastWins[A]: Monoid[Option[A]] = Monoid.instance(
  { 
    case (None, None)   => None
    case (only, None)   => only
    case (None, only)   => only
    case (_   , winner) => winner
  },
  None
)
#+END_SRC

Now everything compiles, let's try it out...

#+BEGIN_SRC scala
scala> import java.time.{LocalDate => LD}
scala> val templates = List(
         TradeTemplate(Nil,                     None,      None),
         TradeTemplate(Nil,                     Some(EUR), None),
         TradeTemplate(List(LD.of(2017, 8, 5)), Some(USD), None),
         TradeTemplate(List(LD.of(2017, 9, 5)), None,      Some(true)),
         TradeTemplate(Nil,                     None,      Some(false))
       )

scala> templates.foldLeft(zero)(_ |+| _)
res: TradeTemplate = TradeTemplate(
                       List(2017-08-05,2017-09-05),
                       Some(USD),
                       Some(false))
#+END_SRC

All we needed to do was implement one piece of business logic and
=Monoid= took care of everything else for us!

Note that the list of =payments= are concatenated. This is because the
default =Monoid[List]= uses concatenation of elements and happens to
be the desired behaviour. If the business requirement was different,
it would be a simple case of providing a custom
=Monoid[List[LocalDate]]=. Recall from Chapter 4 that with compiletime
polymorphism we can have a different implementation of =append=
depending on the =E= in =List[E]=, not just the base runtime class
=List=.

*** Objecty Things

In the chapter on Data and Functionality we said that the JVM's notion
of equality breaks down for many things that we can put into an ADT.
The problem is that the JVM was designed for Java, and =equals= is
defined on =java.lang.Object= whether it makes sense or not. There is
no way to erase =equals= and no way to guarantee that it is
implemented.

However, in FP we prefer typeclasses for polymorphic functionality and
even concepts as simple equality are captured at compiletime.

#+BEGIN_SRC dot :file images/scalaz-comparable.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    Equal
    Show
    Order -> Equal
    Enum -> Order
}
#+END_SRC

#+ATTR_LATEX: :width 5cm
#+CAPTION: 30
#+RESULTS:
[[file:images/scalaz-comparable.png]]

#+BEGIN_SRC scala
@typeclass trait Equal[F]  {
  @op("===") def equal(a1: F, a2: F): Boolean
  @op("/==") def notEqual(a1: F, a2: F): Boolean = !equal(a1, a2)
}
#+END_SRC

Indeed ~===~ (/triple equals/) is more typesafe than ~==~ (/double
equals/) because it can only be compiled when the types are the same
on both sides of the comparison. You'd be surprised how many bugs this
catches.

=equal= has the same implementation requirements as =Object.equals=

- /commutative/ ~f1 === f2~ implies ~f2 === f1~
- /reflexive/ ~f === f~
- /transitive/ ~f1 === f2 && f2 === f3~ implies ~f1 === f3~

By throwing away the universal concept of =Object.equals= we don't
take equality for granted when we construct an ADT, stopping us at
compiletime from expecting equality when there is none.

Continuing the trend of replacing old Java concepts, rather than data
/being a/ =java.lang.Comparable=, they now /have an/ =Order= according
to:

#+BEGIN_SRC scala
@typeclass trait Order[F] extends Equal[F] {
  @op("?|?") def order(x: F, y: F): Ordering

  override  def equal(x: F, y: F): Boolean = ...
  @op("<" ) def lt(x: F, y: F): Boolean = ...
  @op("<=") def lte(x: F, y: F): Boolean = ...
  @op(">" ) def gt(x: F, y: F): Boolean = ...
  @op(">=") def gte(x: F, y: F): Boolean = ...

  def max(x: F, y: F): F = ...
  def min(x: F, y: F): F = ...
  def sort(x: F, y: F): (F, F) = ...
}

sealed abstract class Ordering
object Ordering {
  case object LT extends Ordering
  case object EQ extends Ordering
  case object GT extends Ordering
}
#+END_SRC

Things that have an order may also be discrete, allowing us to walk
successors and predecessors:

#+BEGIN_SRC scala
@typeclass trait Enum[F] extends Order[F] {
  def succ(a: F): F
  def pred(a: F): F
  def min: Option[F]
  def max: Option[F]

  @op("-+-") def succn(n: Int, a: F): F = ...
  @op("---") def predn(n: Int, a: F): F = ...

  @op("|->" ) def fromToL(from: F, to: F): List[F] = ...
  @op("|-->") def fromStepToL(from: F, step: Int, to: F): List[F] = ...
  @op("|=>" ) def fromToL(from: F, to: F): EphemeralStream[F] = ...
  @op("|==>") def fromStepToL(from: F, step: Int, to: F): EphemeralStream[F] = ...
}
#+END_SRC

#+BEGIN_SRC scala
scala> 10 |--> (2, 20)
res: List[Int] = List(10, 12, 14, 16, 18, 20)

scala> 'm' |-> 'u'
res: List[Char] = List(m, n, o, p, q, r, s, t, u)
#+END_SRC

We'll discuss =EphemeralStream= in the next chapter, for now you just
need to know that it is a potentially infinite data structure that
avoids memory retention problems in the stdlib =Stream=.

Similarly to =Object.equals=, the concept of a =.toString= on every
=class= does not make sense in Java. We would like to enforce
stringyness at compiletime and this is exactly what =Show= achieves:

#+BEGIN_SRC scala
trait Show[F] {
  def show(f: F): Cord = Cord(shows(f))
  def shows(f: F): String = show(f).toString
}
#+END_SRC

We'll explore =Cord= in more detail in the chapter on data types, you
need only know that it is an efficient data structure for storing and
manipulating =String=.

Unfortunately, due to Scala's default implicit conversions in
=Predef=, and language level support for =toString= in interpolated
strings, it can be incredibly hard to remember to use =shows= instead
of =toString=.

*** Mappable Things

We're focusing on things that can be mapped over, or traversed, in
some sense:

#+BEGIN_SRC dot :file images/scalaz-mappable.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    subgraph mappable {
      Foldable1 -> Foldable
      Traverse -> Functor
      Traverse -> Foldable
      Traverse1 -> Traverse
      Traverse1 -> Foldable1
    }

    subgraph {
      node [fontcolor=lightgrey,color=lightgrey];
      edge [color=lightgrey];

      Functor -> InvariantFunctor
      Apply -> Functor
      Applicative -> Apply
      Align -> Functor
      Bind -> Apply

      Monad
      "Advanced Monads" [style=dashed]
      "Advanced Monads" -> Monad

      Monad -> Applicative
      Monad -> Bind

      Contravariant -> InvariantFunctor
      Divide -> Contravariant
      Divisible -> Divide
      Cobind -> Functor
      Comonad -> Cobind

      PlusEmpty -> Plus
      IsEmpty -> PlusEmpty

      ApplicativePlus -> Applicative
      ApplicativePlus -> PlusEmpty

      ComonadStore -> Comonad

      BindRec -> Bind
    }
}
#+END_SRC

#+CAPTION: 100
#+RESULTS:
[[file:images/scalaz-mappable.png]]

**** Functor

#+BEGIN_SRC scala
@typeclass trait Functor[F[_]] {
  def map[A, B](fa: F[A])(f: A => B): F[B]

  def void[A](fa: F[A]): F[Unit] = map(fa)(_ => ())
  def fproduct[A, B](fa: F[A])(f: A => B): F[(A, B)] = map(fa)(a => (a, f(a)))

  def fpair[A](fa: F[A]): F[(A, A)] = map(fa)(a => (a, a))
  def strengthL[A, B](a: A, f: F[B]): F[(A, B)] = map(f)(b => (a, b))
  def strengthR[A, B](f: F[A], b: B): F[(A, B)] = map(f)(a => (a, b))

  def lift[A, B](f: A => B): F[A] => F[B] = map(_)(f)
  def mapply[A, B](a: A)(f: F[A => B]): F[B] = map(f)((ff: A => B) => ff(a))
}
#+END_SRC

The only abstract method is =map=, and it must /compose/, i.e. mapping
with =f= and then again with =g= is the same as mapping once with the
composition of =f= and =g=:

#+BEGIN_SRC scala
fa.map(f).map(g) == fa.map(f.andThen(g))
#+END_SRC

The =map= should also perform a no-op if the provided function is
=identity= (i.e. =x => x=)

#+BEGIN_SRC scala
fa.map(identity) == fa

fa.map(x => x) == fa
#+END_SRC

=Functor= defines some convenience methods around =map= that can be
optimised by specific instances. The documentation has been
intentionally omitted in the above definitions to encourage you to
guess what a method does before looking at the implementation. Please
spend a moment studying only the type signature of the following
before reading further:

#+BEGIN_SRC scala
  def void[A](fa: F[A]): F[Unit]
  def fproduct[A, B](fa: F[A])(f: A => B): F[(A, B)]

  def fpair[A](fa: F[A]): F[(A, A)]
  def strengthL[A, B](a: A, f: F[B]): F[(A, B)]
  def strengthR[A, B](f: F[A], b: B): F[(A, B)]

  // harder
  def lift[A, B](f: A => B): F[A] => F[B]
  def mapply[A, B](a: A)(f: F[A => B]): F[B]
#+END_SRC

1. =void= takes an instance of the =F[A]= and always returns an
   =F[Unit]=, it forgets all the values whilst preserving the
   structure.
1. =fproduct= takes the same input as =map= but returns =F[(A, B)]=,
   i.e. it tuples the contents with the result of applying the
   function. This is useful when we wish to retain the input.
1. =fpair= twins all the elements of =A= into a tuple =F[(A, A)]=
1. =strengthL= pairs the contents of an =F[B]= with a constant =A= on
   the left.
1. =strengthR= pairs the contents of an =F[A]= with a constant =B= on
   the right.
1. =lift= takes a function =A => B= and returns a =F[A] => F[B]=. In
   other words, it takes a function over the contents of an =F[A]= and
   returns a function that operates *on* the =F[A]= directly.
1. =mapply= is a mind bender. Say you have an =F[_]= of functions =A
   => B= and a value =A=, then you can get an =F[B]=. It has a similar
   signature to =pure= but requires the caller to provide the =F[A =>
   B]=.

=fpair=, =strengthL= and =strengthR= are here because they are simple
examples of reading type signatures, but they are pretty useless in
the wild. For the remaining typeclasses, we'll skip the niche methods.

**** Foldable

Technically, =Foldable= is for data structures that can be walked to
produce a summary value. However, this undersells the fact that it is
a one-typeclass army that can provide most of what you'd expect to see
in a Collections API.

There are so many methods we are going to have to split them out,
beginning with the abstract methods:

#+BEGIN_SRC scala
@typeclass trait Foldable[F[_]] {
  def foldMap[A, B: Monoid](fa: F[A])(f: A => B): B
  def foldRight[A, B](fa: F[A], z: => B)(f: (A, => B) => B): B
  def foldLeft[A, B](fa: F[A], z: B)(f: (B, A) => B): B = ...
#+END_SRC

An instance of =Foldable= need only implement =foldMap= and
=foldRight= to get all of the functionality in this typeclass,
although methods are typically optimised for specific data structures.

You might recognise =foldMap= by its marketing buzzword name,
*MapReduce*. Given an =F[A]=, a function from =A= to =B=, a zero =B=
and a way to combine =B= (provided by the =Monoid=), we can produce a
summary value of type =B=. There is no enforced operation order,
allowing for parallel computation.

=foldRight= does not require its parameters to have a =Monoid=,
meaning that it needs a starting value =z= and a way to combine each
element of the data structure with the summary value. The order for
traversing the elements is from right to left and therefore it cannot
be parallelised.

#+BEGIN_ASIDE

=foldRight= is conceptually the same as the =foldRight= in the Scala
stdlib. However, there is a problem with the stdlib =foldRight=
signature, solved in scalaz: very large data structures can stack
overflow. =List.foldRight= cheats by implementing =foldRight= as a
reversed =foldLeft=

#+BEGIN_SRC scala
override def foldRight[B](z: B)(op: (A, B) => B): B =
  reverse.foldLeft(z)((right, left) => op(left, right))
#+END_SRC

but the concept of reversing is not universal and this workaround
cannot be used for all data structures. Let's say we want to find
out if there is a small number in a =Stream=, with an early exit:

#+BEGIN_SRC scala
scala> def isSmall(i: Int): Boolean = i < 10
scala> (1 until 100000).toStream.foldRight(false) {
         (el, acc) => isSmall(el) || acc
       }
java.lang.StackOverflowError
  at scala.collection.Iterator.toStream(Iterator.scala:1403)
  ...
#+END_SRC

Scalaz solves the problem by taking a /byname/ parameter for the
aggregate value

#+BEGIN_SRC scala
scala> (1 |=> 100000).foldRight(false)(el => acc => isSmall(el) || acc )
res: Boolean = true
#+END_SRC

which means that the =acc= is not evaluated unless it is needed.

It is worth baring in mind that not all operations are stack safe in
=foldRight=. If we were to require evaluation of all elements, we can
also get a =StackOverflowError= with scalaz's =EphemeralStream=

#+BEGIN_SRC scala
scala> (1L |=> 100000L).foldRight(0L)(el => acc => el |+| acc )
java.lang.StackOverflowError
  at scalaz.Foldable.$anonfun$foldr$1(Foldable.scala:100)
  ...
#+END_SRC
#+END_ASIDE

=foldLeft= traverses elements from left to right. =foldLeft= can be
implemented in terms of =foldMap=, but most instances choose to
implement it because it is such a basic operation. Since it is usually
implemented with tail recursion, there are no /byname/ parameters.

The only law for =Foldable= is that =foldLeft= and =foldRight= should
each be consistent with =foldMap= for monoidal operations. e.g.
appending an element to a list for =foldLeft= and prepending an
element to a list for =foldRight=. However, =foldLeft= and =foldRight=
do not need to be consistent with each other: in fact they often
produce the reverse of each other.

The simplest thing to do with =Foldable= is to use the =identity=
function, the natural sum of the monoidal elements, giving us =fold=
(and left/right variants to allow choosing specific performance
criteria):

#+BEGIN_SRC scala
  def fold[A: Monoid](t: F[A]): A = ...
  def sumr[A: Monoid](fa: F[A]): A = ...
  def suml[A: Monoid](fa: F[A]): A = ...
#+END_SRC

Recall that when we learnt about =Monoid=, we wrote this:

#+BEGIN_SRC scala
scala> templates.foldLeft(Monoid[TradeTemplate].zero)(_ |+| _)
#+END_SRC

We now know this is silly and we should have written:

#+BEGIN_SRC scala
scala> templates.fold
res: TradeTemplate = TradeTemplate(
                       List(2017-08-05,2017-09-05),
                       Some(USD),
                       Some(false))
#+END_SRC

The strangely named =intercalate= inserts a specific =A= between each
element before performing the =fold=

#+BEGIN_SRC scala
  def intercalate[A: Monoid](fa: F[A], a: A): A = ...
#+END_SRC

which is a generalised version of the stdlib's =mkString=:

#+BEGIN_SRC scala
scala> List("foo", "bar").intercalate(",")
res: String = "foo,bar"
#+END_SRC

The =foldLeft= provides the means to obtain any element by traversal
index, including a bunch of other related methods:

#+BEGIN_SRC scala
  def index[A](fa: F[A], i: Int): Option[A] = ...
  def indexOr[A](fa: F[A], default: => A, i: Int): A = ...
  def length[A](fa: F[A]): Int = ...
  def count[A](fa: F[A]): Int = length(fa)
  def empty[A](fa: F[A]): Boolean = ...
  def element[A: Equal](fa: F[A], a: A): Boolean = ...
#+END_SRC

Remember that scalaz is a pure library of only /total functions/ so
=index= returns an =Option=, not an exception like =.apply= in the
stdlib. =index= is like =.get=, =indexOr= is like =.getOrElse= and
=element= is like =.contains= (requiring an =Equal=).

These methods /really/ sound like a collections API. And, of course,
anything with a =Foldable= can be converted into a =List=

#+BEGIN_SRC scala
  def toList[A](fa: F[A]): List[A] = ...
#+END_SRC

There are also conversions to other stdlib and scalaz data types such
as =.toSet=, =.toVector=, =.toStream=, =.to[T <: TraversableLike]=,
=.toIList= and so on.

There are useful predicate checks

#+BEGIN_SRC scala
  def filterLength[A](fa: F[A])(f: A => Boolean): Int = ...
  def all[A](fa: F[A])(p: A => Boolean): Boolean = ...
  def any[A](fa: F[A])(p: A => Boolean): Boolean = ...
#+END_SRC

=filterLength= is a way of counting how many elements are =true= for a
predicate, =all= and =any= return =true= if all (or any) element meets
the predicate, and may exit early.

#+BEGIN_ASIDE
We've seen the =NonEmptyList= in previous chapters. For the sake of
brevity we use a type alias =Nel= in place of =NonEmptyList=.

We've also seen =IList= in previous chapters, recall that it's an
alternative to stdlib =List= with invariant type parameters and all
the impure methods, like =apply=, removed.
#+END_ASIDE

We can split an =F[A]= into parts that result in the same =B= with
=splitBy=

#+BEGIN_SRC scala
  def splitBy[A, B: Equal](fa: F[A])(f: A => B): IList[(B, Nel[A])] = ...
  def splitByRelation[A](fa: F[A])(r: (A, A) => Boolean): IList[Nel[A]] = ...
  def splitWith[A](fa: F[A])(p: A => Boolean): List[Nel[A]] = ...
  def selectSplit[A](fa: F[A])(p: A => Boolean): List[Nel[A]] = ...

  def findLeft[A](fa: F[A])(f: A => Boolean): Option[A] = ...
  def findRight[A](fa: F[A])(f: A => Boolean): Option[A] = ...
#+END_SRC

for example

#+BEGIN_SRC scala
scala> IList("foo", "bar", "bar", "faz", "gaz", "baz").splitBy(_.charAt(0))
res = [(f, [foo]), (b, [bar, bar]), (f, [faz]), (g, [gaz]), (b, [baz])]
#+END_SRC

noting that there are two parts indexed by =f=.

=splitByRelation= avoids the need for an =Equal= but we must provide
the comparison operator.

=splitWith= splits the elements into groups that alternatively satisfy
and don't satisfy the predicate. =selectSplit= selects groups of
elements that satisfy the predicate, discarding others. This is one of
those rare occasions when two methods share the same type signature
but have different meanings.

=findLeft= and =findRight= are for extracting the first element (from
the left, or right, respectively) that matches a predicate.

Making further use of =Equal= and =Order=, we have the =distinct=
methods which return groupings.

#+BEGIN_SRC scala
  def distinct[A: Order](fa: F[A]): IList[A] = ...
  def distinctE[A: Equal](fa: F[A]): IList[A] = ...
  def distinctBy[A, B: Equal](fa: F[A])(f: A => B): IList[A] =
#+END_SRC

=distinct= is implemented more efficiently than =distinctE= because it
can make use of ordering and therefore use a quicksort-esque algorithm
that is much faster than the stdlib's naive =List.distinct=. Data
structures (such as sets) can implement =distinct= in their =Foldable=
without doing any work.

=distinctBy= allows grouping by the result of applying a function to
the elements. For example, grouping names by their first letter.

We can make further use of =Order= by extracting the minimum or
maximum element (or both extrema) including variations using the =Of=
or =By= pattern to first map to another type or to use a different
type to do the order comparison.

#+BEGIN_SRC scala
  def maximum[A: Order](fa: F[A]): Option[A] = ...
  def maximumOf[A, B: Order](fa: F[A])(f: A => B): Option[B] = ...
  def maximumBy[A, B: Order](fa: F[A])(f: A => B): Option[A] = ...

  def minimum[A: Order](fa: F[A]): Option[A] = ...
  def minimumOf[A, B: Order](fa: F[A])(f: A => B): Option[B] = ...
  def minimumBy[A, B: Order](fa: F[A])(f: A => B): Option[A] = ...

  def extrema[A: Order](fa: F[A]): Option[(A, A)] = ...
  def extremaOf[A, B: Order](fa: F[A])(f: A => B): Option[(B, B)] = ...
  def extremaBy[A, B: Order](fa: F[A])(f: A => B): Option[(A, A)] =
#+END_SRC

For example we can ask which =String= is maximum =By= length, or what
is the maximum length =Of= the elements.

#+BEGIN_SRC scala
scala> List("foo", "fazz").maximumBy(_.length)
res: Option[String] = Some(fazz)

scala> List("foo", "fazz").maximumOf(_.length)
res: Option[Int] = Some(4)
#+END_SRC

This concludes the key features of =Foldable=. You are forgiven for
already forgetting all the methods you've just seen: the key takeaway
is that anything you'd expect to find in a collection library is
probably on =Foldable= and if it isn't already, it [[https://github.com/scalaz/scalaz/issues/1448][probably should be]].

We'll conclude with some variations of the methods we've already seen.
First there are methods that take a =Semigroup= instead of a =Monoid=:

#+BEGIN_SRC scala
  def fold1Opt[A: Semigroup](fa: F[A]): Option[A] = ...
  def foldMap1Opt[A, B: Semigroup](fa: F[A])(f: A => B): Option[B] = ...
  def sumr1Opt[A: Semigroup](fa: F[A]): Option[A] = ...
  def suml1Opt[A: Semigroup](fa: F[A]): Option[A] = ...
  ...
#+END_SRC

returning =Option= to account for empty data structures (recall that
=Semigroup= does not have a =zero=). Note that the methods read
"one-Option", not =10 pt=, a subtle typesetting joke for the
(un-)observant.

The typeclass =Foldable1= contains a lot more =Semigroup= variants of
the =Monoid= methods shown here (all suffixed =1=) and makes sense for
data structures which are never empty, without requiring a =Monoid= on
the elements.

Very importantly, there are variants that take monadic return values.
We already used =foldLeftM= when we first wrote the business logic of
our application, now you know that =Foldable= is where it came from:

#+BEGIN_SRC scala
def foldLeftM[G[_]: Monad, A, B](fa: F[A], z: B)(f: (B, A) => G[B]): G[B] = ...
def foldRightM[G[_]: Monad, A, B](fa: F[A], z: => B)(f: (A, => B) => G[B]): G[B] = ...
def foldMapM[G[_]: Monad, A, B: Monoid](fa: F[A])(f: A => G[B]): G[B] = ...
def findMapM[M[_]: Monad, A, B](fa: F[A])(f: A => M[Option[B]]): M[Option[B]] = ...
def allM[G[_]: Monad, A](fa: F[A])(p: A => G[Boolean]): G[Boolean] = ...
def anyM[G[_]: Monad, A](fa: F[A])(p: A => G[Boolean]): G[Boolean] = ...
...
#+END_SRC

You may also see Curried versions, e.g.

#+BEGIN_SRC scala
def foldl[A, B](fa: F[A], z: B)(f: B => A => B): B = ...
def foldr[A, B](fa: F[A], z: => B)(f: A => (=> B) => B): B = ...
...
#+END_SRC

which are elegant signatures for the more civilised hacker.

**** Traverse

=Traverse= is what happens when you cross a =Functor= with a =Foldable=

#+BEGIN_SRC scala
trait Traverse[F[_]] extends Functor[F] with Foldable[F] {
  def traverse[G[_]: Applicative, A, B](fa: F[A])(f: A => G[B]): G[F[B]]
  def sequence[G[_]: Applicative, A](fga: F[G[A]]): G[F[A]] = ...

  def reverse[A](fa: F[A]): F[A] = ...

  def zipL[A, B](fa: F[A], fb: F[B]): F[(A, Option[B])] = ...
  def zipR[A, B](fa: F[A], fb: F[B]): F[(Option[A], B)] = ...
  def indexed[A](fa: F[A]): F[(Int, A)] = ...
  def zipWithL[A, B, C](fa: F[A], fb: F[B])(f: (A, Option[B]) => C): F[C] = ...
  def zipWithR[A, B, C](fa: F[A], fb: F[B])(f: (Option[A], B) => C): F[C] = ...

  def mapAccumL[S, A, B](fa: F[A], z: S)(f: (S, A) => (S, B)): (S, F[B]) = ...
  def mapAccumR[S, A, B](fa: F[A], z: S)(f: (S, A) => (S, B)): (S, F[B]) = ...
}
#+END_SRC

At the beginning of the chapter we showed the importance of =traverse=
and =sequence= for swapping around HKTs to fit a requirement (e.g.
=List[Future[_]]= to =Future[List[_]]=). You will use these methods
more than you could possibly imagine.

In =Foldable= we weren't able to assume that =reverse= was a universal
concept, but now we can reverse a thing.

We can also =zip= together two things that have a =Traverse=, getting
back =None= when one side runs out of elements, using =zipL= or =zipR=
to decide which side to truncate when the lengths don't match. A
special case of =zip= is to add an index to every entry with
=indexed=.

=zipWithL= and =zipWithR= allow combining the two sides of a =zip=
into a new type, and then returning just an =F[C]=.

=mapAccumL= and =mapAccumR= are regular =map= combined with an
accumulator. If you find your old Java sins are making you want to
reach for a =var=, and refer to it from a =map=, you want =mapAccumL=.

For example, let's say we have a list of words and we want to blank
out words we've already seen. The filtering algorithm is not allowed
to process the list of words a second time so it can be scaled to an
infinite stream:

#+BEGIN_SRC scala
scala> val freedom =
"""We campaign for these freedoms because everyone deserves them.
   With these freedoms, the users (both individually and collectively)
   control the program and what it does for them."""
   .split("\\s+")
   .toList

scala> def clean(s: String): String = s.toLowerCase.replaceAll("[,.()]+", "")

scala> freedom
       .mapAccumL(Set.empty[String]) { (seen, word) =>
         val cleaned = clean(word)
         (seen + cleaned, if (seen(cleaned)) "_" else word)
       }
       ._2
       .intercalate(" ")

res: String =
"""We campaign for these freedoms because everyone deserves them.
   With _ _ the users (both individually and collectively)
   control _ program _ what it does _ _"""
#+END_SRC

Finally =Traverse1=, like =Foldable1=, provides variants of these
methods for data structures that cannot be empty, accepting the weaker
=Semigroup= instead of a =Monoid=, and an =Apply= instead of an
=Applicative=.

*** Variance

We must return to =Functor= for a moment and discuss an ancestor that
we previously ignored:

#+BEGIN_SRC dot :file images/scalaz-variance.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    subgraph mappable {
      Contravariant -> InvariantFunctor
      Functor -> InvariantFunctor
    }

    subgraph {
      node [fontcolor=lightgrey,color=lightgrey];
      edge [color=lightgrey];

      Divide -> Contravariant
      Divisible -> Divide
      Apply -> Functor

      Foldable1 -> Foldable
      Traverse -> Functor
      Traverse -> Foldable
      Traverse1 -> Traverse
      Traverse1 -> Foldable1

      Applicative -> Apply
      Align -> Functor
      Bind -> Apply
      Monad 

      "Advanced Monads" [style=dashed]
      "Advanced Monads" -> Monad

      Monad -> Applicative
      Monad -> Bind

      Cobind -> Functor
      Comonad -> Cobind

      PlusEmpty -> Plus
      IsEmpty -> PlusEmpty

      ApplicativePlus -> Applicative
      ApplicativePlus -> PlusEmpty

      ComonadStore -> Comonad

      BindRec -> Bind
    }
}
#+END_SRC

#+CAPTION: 100
#+RESULTS:
[[file:images/scalaz-variance.png]]

=InvariantFunctor=, also known as the /exponential functor/, has a
method =xmap= which says that given a function from =A= to =B=, and a
function from =B= to =A=, then we can convert =F[A]= to =F[B]=.

=Functor= is a short name for what should be /covariant functor/. But
since =Functor= is so popular it gets the nickname. Likewise
=Contravariant= should really be /contravariant functor/.

=Functor= implements =xmap= with =map= and ignores the function from
=B= to =A=. =Contravariant=, on the other hand, implements =xmap= with
=contramap= and ignores the function from =A= to =B=:

#+BEGIN_SRC scala
@typeclass trait InvariantFunctor[F[_]] {
  def xmap[A, B](fa: F[A], f: A => B, g: B => A): F[B]
  ...
}

@typeclass trait Functor[F[_]] extends InvariantFunctor[F] {
  def map[A, B](fa: F[A])(f: A => B): F[B]
  def xmap[A, B](fa: F[A], f: A => B, g: B => A): F[B] = map(fa)(f)
  ...
}

@typeclass trait Contravariant[F[_]] extends InvariantFunctor[F] {
  def contramap[A, B](fa: F[A])(f: B => A): F[B]
  def xmap[A, B](fa: F[A], f: A => B, g: B => A): F[B] = contramap(fa)(f)
  ...
}
#+END_SRC

It is important to note that, although related at a theoretical level,
the words /covariant/, /contravariant/ and /invariant/ do not directly
refer to type variance (i.e. =+= and =-= prefixes that may be written
in type signatures). /Invariance/ here means that it is possible to
map the contents of a structure =F[A]= into =F[B]=.

This is so ridiculously abstract and seemingly impossible that it
needs a practical example immediately, before we can continue on good
terms. In Chapter 4 we used circe to derive a JSON encoder for our
data types and we gave a brief description of the =Encoder= typeclass.
This is an expanded version:

#+BEGIN_SRC scala
@typeclass trait Encoder[A] { self =>
  def encodeJson(a: A): Json

  def contramap[B](f: B => A): Encoder[B] = new Encoder[B] {
    def encodeJson(b: B): Json = self(f(b))
  }
}
#+END_SRC

Now consider the case where we want to write an instance of an
=Encoder[B]= in terms of another =Encoder[A]=. That's exactly what
=contramap= is for (recall that it is safe to call =Some.get=, but not
=Option.get=):

#+BEGIN_SRC scala
implicit def some[A: Encoder]: Encoder[Some[A]] = Encoder[A].contramap(_.get)
#+END_SRC

On the other hand, a =Decoder= typically has a =Functor=:

#+BEGIN_SRC scala
@typeclass trait Decoder[A] { self =>
  def decodeJson(j: Json): Decoder.Result[A]

  def map[B](f: A => B): Decoder[B] = new Decoder[B] {
    def decodeJson(j: Json): Decoder.Result[B] = self.decodeJson(j).map(f)
  }
}
object Decoder {
  type Result[A] = Either[String, A]
}
#+END_SRC

Methods on a typeclass can have their type parameters in
/contravariant position/ (method parameters) or in /covariant
position/ (return type). If a typeclass has a combination of covariant
and contravariant positions, it might have an /invariant functor/.

Consider what happens if we combine =Encoder= and =Decoder= into one
typeclass. We can no longer construct a =Format= by using =map= or
=contramap= alone, we need =xmap=:

#+BEGIN_SRC scala
@typeclass trait Format[A] extends Encoder[A] with Decoder[A] { self =>
  def xmap[B](f: A => B, g: B => A): Format[B] = new Format[B] {
    def encodeJson(b: B): Json = self(g(b))
    def decodeJson(j: Json): Decoder.Result[B] = self.decodeJson(j).map(f)
  }
}
#+END_SRC

#+BEGIN_ASIDE
Although =Encoder= implements =contramap=, =Decoder= implements =map=,
and =Format= implements =xmap= we are not saying that these
typeclasses extend =InvariantFunctor=, rather they /have an/
=InvariantFunctor=.

We could implement instances of

- =Functor[Decoder]=
- =Contravariant[Encoder]=
- =InvariantFunctor[Format]=

on our companions, and use scalaz syntax to have the exact same =map=,
=contramap= and =xmap=.

However, since we don't need anything else that the invariants provide
(and it's a lot of boilerplate for a textbook), we just implement the
bare minimum on the typeclasses themselves. The invariant instance
[[https://github.com/mpilquist/simulacrum/issues/85][could be generated automatically]].
#+END_ASIDE

One of the most compelling uses for =xmap= is to provide typeclasses
for /value types/. A value type is a compiletime wrapper for another
type, that does not incur any object allocation costs (subject to some
rules of use).

For example we can provide context around some numbers to avoid
getting them mixed up:

#+BEGIN_SRC scala
final case class Alpha(value: Double) extends AnyVal
final case class Beta (value: Double) extends AnyVal
final case class Rho  (value: Double) extends AnyVal
final case class Nu   (value: Double) extends AnyVal
#+END_SRC

If we want to put these types in a JSON message, we'd need to write a
custom =Format= for each type, which is tedious. But our =Format=
implements =xmap=, allowing =Format= to be constructed from a simple
pattern:

#+BEGIN_SRC scala
implicit val double: Format[Double] = ...

implicit val alpha: Format[Alpha] = double.xmap(Alpha(_), _.value)
implicit val beta : Format[Beta]  = double.xmap(Beta(_) , _.value)
implicit val rho  : Format[Rho]   = double.xmap(Rho(_)  , _.value)
implicit val nu   : Format[Nu]    = double.xmap(Nu(_)   , _.value)
#+END_SRC

Macros can automate the construction of these instances, so we don't
need to write them: we'll revisit this later in a dedicated chapter on
Typeclass Derivation.

**** Composition

Invariants can be composed via methods with intimidating type
signatures. There are many permutations of =compose= on most
typeclasses, we will not list them all.

#+BEGIN_SRC scala
@typeclass trait Functor[F[_]] extends Invariant[F] {
  def compose[G[_]: Functor]: Functor[λ[α => F[G[α]]]] = ...
  def icompose[G[_]: Contravariant]: Contravariant[λ[α => F[G[α]]]] = ...
  ...
}
@typeclass trait Contravariant[F[_]] extends Invariant[F] {
  def compose[G[_]: Contravariant]: Functor[λ[α => F[G[α]]]] = ...
  def icompose[G[_]: Functor]: Contravariant[λ[α => F[G[α]]]] = ...
  ...
}
#+END_SRC

The arrow syntax is a =kind-projector= /type lambda/ that says, for
example, if =Functor[F]= is composed with a type =G[_]= (that has a
=Functor[G]=), we get a =Functor[F[G[_]]]= that can operate on
=F[G[A]]=.

An example of =Functor.compose= is where =F[_]= is =List=, =G[_]= is
=Option=, and we want to be able to map over the =Int= inside a
=List[Option[Int]]= without changing the two structures:

#+BEGIN_SRC scala
scala> val lo = List(Some(1), None, Some(2))
scala> Functor[List].compose[Option].map(lo)(_ + 1)
res: List[Option[Int]] = List(Some(2), None, Some(3))
#+END_SRC

This lets us jump into nested effects and structures and apply a
function at the layer we want.

*** Everything But Pure

=Apply= is =Applicative= without the =pure= method, and =Bind= is
=Monad= without =pure=. Consider this the warm-up act, with an
Advanced TIE Fighter for entertainment.

#+BEGIN_SRC dot :file images/scalaz-applicative.png :exports results
digraph G {
    graph [dpi=100, rankdir=BT];
    node [fontname=Hack];

    subgraph mappable {
      Bind -> Apply
      BindRec -> Bind
    }

    subgraph {
      node [fontcolor=lightgrey,color=lightgrey];
      edge [color=lightgrey];

      Contravariant -> InvariantFunctor
      Functor -> InvariantFunctor

      Divide -> Contravariant
      Divisible -> Divide
      Apply -> Functor
      Applicative -> Apply

      Foldable1 -> Foldable
      Traverse -> Functor
      Traverse -> Foldable
      Traverse1 -> Traverse
      Traverse1 -> Foldable1

      Align -> Functor
      Monad 

      "Advanced Monads" [style=dashed]
      "Advanced Monads" -> Monad

      Monad -> Applicative
      Monad -> Bind

      Cobind -> Functor
      Comonad -> Cobind

      PlusEmpty -> Plus
      IsEmpty -> PlusEmpty

      ApplicativePlus -> Applicative
      ApplicativePlus -> PlusEmpty

      ComonadStore -> Comonad
    }
}
#+END_SRC

#+CAPTION: 100
#+RESULTS:
[[file:images/scalaz-applicative.png]]

**** Apply

=Apply= extends =Functor= by adding a method named =ap= which is
similar to =map= in that it applies a function to values. However,
with =ap=, the function is in the same context as the values.

#+BEGIN_SRC scala
@typeclass trait Apply[F[_]] extends Functor[F] {
  @op("<*>") def ap[A, B](fa: => F[A])(f: => F[A => B]): F[B]

  def apply2[A,B,C](fa: =>F[A],fb: =>F[B])(f: (A,B) =>C): F[C] = ...
  def apply3[A,B,C,D](fa: =>F[A],fb: =>F[B],fc: =>F[C])(f: (A,B,C) =>D): F[D] = ...
  ...
  def apply12[...]
#+END_SRC

The =applyX= boilerplate allows us to combine parallel functions and
then map over their combined output. Although it's /possible/ to use
=<*>= on data structures, it is far more valuable when operating on
/effects/ like the drone and google algebras we created in Chapter 3.

=Apply= has special syntax:

#+BEGIN_SRC scala
implicit class ApplyOps[F[_]: Apply, A](val self: F[A]) {
  def *>[B](fb: F[B]): F[B] = Apply[F].apply2(self,fb)((_,b) => b)
  def <*[B](fb: F[B]): F[A] = Apply[F].apply2(self,fb)((a,_) => a)
  def |@|[B](fb: F[B]): ApplicativeBuilder[F, A, B] = ...
}

class ApplicativeBuilder[F[_]: Apply, A, B](a: F[A], b: F[B]) {
  def tupled: F[(A, B)] = Apply[F].apply2(a, b)(f)
  def |@|[C](cc: F[C]): ApplicativeBuilder3[C] = ...

  sealed abstract class ApplicativeBuilder3[C](c: F[C]) {
    ..ApplicativeBuilder4
      ...
        ..ApplicativeBuilder12
}
#+END_SRC

which is exactly what we used in Chapter 3:

#+BEGIN_SRC scala
(d.getBacklog |@| d.getAgents |@| m.getManaged |@| m.getAlive |@| m.getTime)
#+END_SRC

#+BEGIN_ASIDE
The =|@|= operator has many names. Some call it the /Cartesian Product
Syntax/, others call it the /Cinnamon Bun/, the /Admiral Ackbar/ or
the /Macaulay Culkin/. We prefer to call it /The Scream/ operator,
after the Munch painting, because it is also the sound your CPU makes
when it is parallelising All The Things.
#+END_ASIDE

The syntax =*>= and =<*= offer a convenient way to ignore the output
from one of two parallel effects.

Unfortunately, although the =|@|= syntax is clear there is a problem
in that a new =ApplicativeBuilder= object is allocated for each
additional effect. If the work is I/O-bound, the memory allocation
cost is insignificant. However, when performing CPU-bound work, use
the alternative /lifting with arity/ syntax, which does not produce
any intermediate objects:

#+BEGIN_SRC scala
def ^[F[_]: Apply,A,B,C](fa: =>F[A],fb: =>F[B])(f: (A,B) =>C): F[C] = ...
def ^^[F[_]: Apply,A,B,C,D](fa: =>F[A],fb: =>F[B],fc: =>F[C])(f: (A,B,C) =>D): F[D] = ...
...
def ^^^^^^[F[_]: Apply, ...]
#+END_SRC

used like

#+BEGIN_SRC scala
^^^^(d.getBacklog, d.getAgents, m.getManaged, m.getAlive, m.getTime)
#+END_SRC

or directly call =applyX=

#+BEGIN_SRC scala
Apply[F].apply5(d.getBacklog, d.getAgents, m.getManaged, m.getAlive, m.getTime)
#+END_SRC

Despite being of most value for dealing with effects, =Apply= provides
convenient syntax for dealing with data structures. Consider rewriting

#+BEGIN_SRC scala
  for {
    foo <- data.foo: Option[String]
    bar <- data.bar: Option[Int]
  } yield foo + bar.shows
#+END_SRC

as

#+BEGIN_SRC scala
(data.foo |@| data.bar)(_ + _.shows) : Option[String]

#+END_SRC

If we only want the combined output as a tuple, methods exist to do
just that:

#+BEGIN_SRC scala
  @op("tuple") def tuple2[A,B](fa: =>F[A],fb: =>F[B]): F[(A,B)] = ...
  def tuple3[A,B,C](fa: =>F[A],fb: =>F[B],fc: =>F[C]): F[(A,B,C)] = ...
  ...
  def tuple12[...]
#+END_SRC

#+BEGIN_SRC scala
(data.foo tuple data.bar) : Option[(String, Int)]
#+END_SRC

There are also the generalised versions of =ap= for more than two
parameters:

#+BEGIN_SRC scala
  def ap2[A,B,C](fa: =>F[A],fb: =>F[B])(f: F[(A,B) =>C]): F[C] = ...
  def ap3[A,B,C,D](fa: =>F[A],fb: =>F[B],fc: =>F[C])(f: F[(A,B,C) =>D]): F[D] = ...
  ...
  def ap12[...]
#+END_SRC

along with =lift= methods that take normal functions and lift them into the
=F[_]= context, the generalisation of =Functor.lift=

#+BEGIN_SRC scala
  def lift2[A,B,C](f: (A,B) =>C): (F[A],F[B]) =>F[C] = ...
  def lift3[A,B,C,D](f: (A,B,C) =>D): (F[A],F[B],F[C])=>F[D] = ...
  ...
  def lift12[...]
#+END_SRC

and =apF=, a partially applied syntax for =ap=

#+BEGIN_SRC scala
  def apF[A,B](f: => F[A => B]): F[A] => F[B] = ...
#+END_SRC

Finally =forever=

#+BEGIN_SRC scala
  def forever[A, B](fa: F[A]): F[B] = ...
#+END_SRC

repeating an effect without stopping. The instance of =Apply= must be
stack safe or we'll get =StackOverflowError=.

**** Bind and BindRec

=Bind= introduces =bind=, synonymous with =flatMap=, which allows
functions on values to return a value in a context, which is then
bound to original context.

#+BEGIN_SRC scala
@typeclass trait Bind[F[_]] extends Apply[F] {

  @op(">>=") def bind[A, B](fa: F[A])(f: A => F[B]): F[B]
  def flatMap[A, B](fa: F[A])(f: A => F[B]): F[B] = bind(fa)(f)

  def join[A](ffa: F[F[A]]): F[A] = bind(ffa)(identity)

  def ifM[B](value: F[Boolean], t: =>F[B], f: =>F[B]): F[B] = ...
  def mproduct[A, B](fa: F[A])(f: A => F[B]): F[(A, B)] = ...

}
#+END_SRC

The =join= may be familiar if you have ever used =flatten= in the
stdlib, it takes nested contexts and squashes then into one.

=ifM= is a convenient and optimised way to construct a conditional
data structure or effect:

#+BEGIN_SRC scala
scala> List(true, false, true).ifM(List(0), List(1, 1))
res: List[Int] = List(0, 1, 1, 0)
#+END_SRC

Note that, as is the case with =bind=, results are joined. Although
not necessarily implemented as such, you can think of =bind= as being
a =Functor.map= followed by =join=

#+BEGIN_SRC scala
def bind[A, B](fa: F[A])(f: A => F[B]): F[B] = join(map(fa)(f))
#+END_SRC

=ifM= is optimised to cache and reuse the branches as they are used,
compare to the longer form

#+BEGIN_SRC scala
scala> List(true, false, true).flatMap { b => if (b) List(0) else List(1, 1) }
#+END_SRC

which produces a fresh =List(0)= or =List(1, 1)= every time the branch
is invoked. =ap= is optimised in the name manner.

#+BEGIN_ASIDE
These kinds of optimisations are possible in FP because all methods
are deterministic, also known as /referentially transparent/.

If a method returns a different value every time it is called, it is
/impure/ and breaks the reasoning and optimisations that we can
otherwise make.

If the =F= is an effect, perhaps one of our drone or Google algebras,
it does not mean that the output of the call to the algebra is cached.
Rather the reference to the operation is cached. The performance
optimisation of =ifM= is only noticeable for data structures, and more
pronounced with the difficulty of the work in each branch.

We will explore the concept of determinism in more detail in the next
chapter.
#+END_ASIDE

# TODO: mproduct
# TODO: BindRec

# *** TODO Applicative and Monad
# *** TODO Align
# *** TODO Divide and Divisable
# *** TODO Plus, PlusEmpty, IsEmpty, ApplicativePlus

# These were cut from Foldable, revisit them...
# #+BEGIN_SRC scala
#   def msuml[G[_]: PlusEmpty, A](fa: F[G[A]]): G[A] = ...
#   def collapse[X[_]: ApplicativePlus, A](x: F[A]): X[A] = ...
# #+END_SRC

# *** TODO Zip, Unzip
# *** TODO Lone Wolves
# **** TODO Optional
# **** TODO Associative
# **** TODO Catchable
# **** TODO Resource
# *** TODO Co-things: Cobind, Comonad, ComonadStore, Cozip
# *** TODO Bi-things: Bifunctor, Bifoldable, Bitraverse
# *** TODO Very Abstract Things
# Compose, Category, Split, Choice, Arrow, Strong, Profunctor, ProChoice

** What's Next?

You've reached the end of this Early Access book. Please check the
website regularly for updates.

You can expect to see chapters covering the following topics:

- Scalaz Typeclasses (completed)
- Scalaz Data Types
- Scalaz Advanced Monads
- Scalaz Utilities
- Functional Streams
- Type Refinement
- Generic Derivation
- Recursion Schemes
- Dependent Types
- Optics
- Category Theory

while continuing to build out the example application.

* TODO Remaining
  :PROPERTIES:
  :EXPORT_FILE_NAME: remaining.md
  :END:
** Data Types

 Adjunction
 Alpha
 Alter
 Ap
 Band
 Bias
 BijectionT
 CaseInsensitive
 Codensity
 Cofree
 Cokleisli
 ComonadTrans
 Composition
 Const
 ContravariantCoyoneda
 Coproduct
 Cord
 CorecursiveList
 Coyoneda
 Dequeue
 Diev
 Digit  // revisit the Foldable method
 Distributive
 DList
 Dual
 Either3
 Either
 EitherT
 Endomorphic
 Endo
 EphemeralStream
 FingerTree
 Forall
 FreeAp
 Free
 FreeT
 Generator
 Heap
 Id
 IdT
 IList
 ImmutableArray
 IndexedContsT
 Injective
 Inject
 ISet
 Isomorphism
 Kan
 Kleisli
 LazyEither
 LazyEitherT
 LazyOption
 LazyOptionT
 LazyTuple
 Leibniz
 Lens
 Liskov
 ListT
 Map
 Maybe
 MaybeT
 Memo
 MonadListen
 MonadTrans
 MonoidCoproduct
 Name
 NaturalTransformation
 NonEmptyList
 NotNothing
 NullArgument
 NullResult
 OneAnd
 OneOr
 OptionT
 Ordering
 PLens
 Product
 ReaderWriterStateT
 Reducer
 Representable
 State
 StateT
 StoreT
 StreamT
 StrictTree
 Tag
 Tags
 These
 TheseT
 TracedT
 TreeLoc
 Tree
 Unapply
 UnwriterT
 Validation
 WriterT
 Yoneda
 Zap
 Zipper

**** Liskov / Subtyping

https://failex.blogspot.co.uk/2016/09/the-missing-diamond-of-scala-variance.html?spref=tw
https://typelevel.org/blog/2016/09/19/variance-phantom.html

After seven major releases over a decade, scalaz has concluded that
Scala's subtyping is fundamentally broken: from subtle bugs in the
compiler to puzzlers that are technically behaving as expected. The
solution is to avoid using covariant and contravariant (=+= and =-=)
type parameter markers.

You'll will notice that many of the data types in scalaz are invariant
in their type parameters. =IList= is =IList[A]= not =List[+A]= for
this very reason.

Instead, the ability to upcast is provided by =Functor=:

#+BEGIN_SRC scala
@typeclass trait Functor[F[_]] extends Invariant[F] {
  def widen[A, B](fa: F[A])(implicit ev: A <~< B): F[B] = ...
  ...
}
#+END_SRC

https://issues.scala-lang.org/browse/SI-2509

#+BEGIN_SRC scala
(on subtyping on typeclasses)

<aarvar> "def foo[F[_] : MonadReader[R, ?] : MonadState[S, ?]] will lead to
         ambiguities if both MonadReader and MonadState extend Monad"
<aarvar> try it  [22:54]
<fommil> yes, and the more common problem is when you want an Applicative and
         a Monad. I'm aware of that problem.
<aarvar> likewise if you have both Applicative and Traversable, the Functor
         instance will be ambiguous, I think
<fommil> but what of when covariant and contravariant type parameters are
         introduced?
<puffnfresh> def foo[F[_]: Monad: Traverse](fa: F[A]): F[Unit] = fa.void
...
<fommil> but what about on ADTs? Why are all the scalaz data types invariant
         rather than covariant?
<fommil> is there a similar implicit resolution problem that is being worked
         around? Or something deeper  [23:00]
<aarvar> fommil: one simple reason is that then Foo[String] and Foo[Int] will
         unify to the common super type Foo[Any], which is almost never what
         you want  [23:02]
<fommil> right... or more commonly Product with Serializable with OtherCrap
#+END_SRC


**** TODO NonEmptyList
**** TODO NonEmptyVector
**** TODO Validated

#+BEGIN_ASIDE
This ADT has methods on it, but in Chapter 4 we said that ADTs
shouldn't have methods on them and that the functionality should live
on typeclasses! You caught us red handed. There are several reasons
for doing it this way.

Sorry, but there are more methods than the =value= and =memoize= on
=Eval= shown here: it also has =map= and =flatMap=. The reason they
live on the ADT and not in an instance of =Monad= is because it is
slightly more efficient for the compiler to find these methods instead
of looking for =Monad.ops._=, and it is slightly more efficient at
runtime. This is an optimisation step that is absolutely vital in a
core library such as cats, but please do not perform these
optimisations in user code unless you have profiled and found a
performance bottleneck. There is a significant cost to code
readability.
#+END_ASIDE

**** TODO Ior

**** TODO Esoteric / Advanced

Maybe leave until after typeclasses

- Cokleisli
- Const
- Coproduct
- Func
- Kleisli
- Nested
- OneAnd
- Prod

**** TODO Monad Transformers

- EitherT
- IdT
- OptionT
- StateT
- WriterT

** TODO Advanced Monads

You have to know things like Advanced Monads in order to be
an advanced functional programmer.

incl monad transformers

functor and applicative compose, monad doesn't, it's annoying, one or two detailed examples but mostly just listing what is available.

i.e. Effects

And also the issue of parallelisation of applicatives vs the sequential nature of Monad

https://www.irccloud.com/pastebin/dx1r05od/

#+BEGIN_SRC scala
trait ApMonad[F[_], G[_]] {
  def to[A](fa: F[A]): G[A]
  def from[A](ga: G[A]): F[A]
  implicit val fmonad: Monad[F]
  implicit val gap: Applicative[G]
}
#+END_SRC

*** TODO Free Monad

- FIXME this is old text, need to rewrite Chapter 3 using explicit scalaz Free Monad boilerplate

What we've been doing in this chapter is using the /free monad/,
=cats.free.Free=, to build up the definition of our program as a data
type and then we interpret it. Freestyle calls it =FS=, which is just
a type alias to =Free=, hiding an irrelevant type parameter.

The reason why we use =Free= instead of just implementing =cats.Monad=
directly (e.g. for =Id= or =Future=) is an unfortunate consequence of
running on the JVM. Every nested call to =map= or =flatMap= adds to
the stack, eventually resulting in a =StackOverflowError=.

=Free= is a =sealed abstract class= that roughly looks like:

#+BEGIN_SRC scala
  sealed abstract class Free[S[_], A] {
    def pure(a: A): Free[S, A] = Pure(a)
    def map[B](f: A => B): Free[S, B] = flatMap(a => Pure(f(a)))
    def flatMap[B](f: A => Free[S, B]): Free[S, B] = FlatMapped(this, f)
  }

  final case class Pure[S[_], A](a: A) extends Free[S, A]
  final case class Suspend[S[_], A](a: S[A]) extends Free[S, A]
  final case class FlatMapped[S[_], B, C](
                                    c: Free[S, C],
                                    f: C => Free[S, B]) extends Free[S, B]
#+END_SRC

Its definition of =pure= / =map= / =flatMap= do not do any work, they
just build up data types that live on the heap. Work is delayed until
Free is /interpreted/. This technique of using heap objects to
eliminate stack growth is known as /trampolining/.

When we use the =@free= annotation, a =sealed abstract class= data
type is generated for each of our algebras, with a =final case class=
per method, allowing trampolining. When we write a =Handler=,
Freestyle is converting pattern matches over heap objects into method
calls.

**** Free as in Monad

=Free[S[_], A]= can be /generated freely/ for any choice of =S=, hence
the name. However, from a practical point of view, there needs to be a
=Monad[S]= in order to interpret it --- so it's more like an interest
only mortgage where you still have to buy the house at the end.

** TODO Utilities

**** TODO [[https://github.com/vil1/single_page_fp_book][single page fp book]]
**** TODO cheat sheet
**** TODO Other

e.g. conversion utilities between things

*** TODO Laws

*** TODO Extensions
** TODO FS2

Task, Stream

The basics, and covering the Effect, which can be our free monad.

Why streams are so awesome. I'd like a simple example here of reading
from a huge data source, doing parallel work and then writing out in
order to a (slower) device to demonstrate backpressure and constant
memory overhead. Maybe compare this vs hand rolled and akka streams
for a perf test?

Rewrite our business logic to be streaming, convert our GET api into a
=Stream= by polling.

** TODO Implementing the Application

Pad out the application implementation with everything we've learnt.

May need union types, see https://github.com/propensive/totalitarian

Will probably be a big chapter. Maybe best to leave it for a final
part of the book?

*** TODO Spotting patterns, refactoring

Note that some of our algebras are actually common things and can be
rewritten: reader / writer / state / error / indexed monad. It's ok
that this is a step you can do later.

**** RESEARCH perf numbers

** TODO Dependent Types

Jons talks are usually good for this https://www.youtube.com/watch?v=a1whaMzrtsY

** TODO Type Refinement
instead of needing those =error= calls in the first place, just don't
allow them to happen at your layer if you can get away with it.

Protect yourself from mistyping

** TODO Generic Programming

- a mini Shapeless for Mortals
- typeclass derivation (UrlEncoding, QueryEncoding)
- scalacheck-shapeless
- cachedImplicit into a val
- downside is compile time speeds for ADTs of 50+
- alternative is https://github.com/propensive/magnolia
- export-hook
- some advanced cases, e.g. spray-json-shapeless stuff, typeclass
  hierarchy / ambiguities
- https://issues.scala-lang.org/browse/SI-2509
- gotchas with nested =object= and knownSubclasses
- semi-auto

** TODO Recursion Schemes
** TODO Optics

not sure what the relevance to this project would be yet.

** TODO Category Theory

Just some of the high level concepts, where to get started if you're interested.
Not needed to write FP but it is needed if you want to read any academic papers.

*** Reality Check

In this chapter we've experienced some of the practical benefits of FP
when designing and testing applications:

1. clean separation of components
2. isolated, fast and reproducible tests of business logic: extreme mocking
3. easy parallelisation

However, even if we look past the learning curve of FP, there are
still some real challenges that remain:

1. trampolining has a performance impact due to increased memory churn
   and garbage collection pressure.
2. there is not always IDE support for the advanced language features,
   macros or compiler plugins.
3. implementation details --- as we have already seen with =for=
   syntax sugar, =@module=, and =Free= --- can introduce mental
   overhead and become a blocker when they don't work.
4. the distinction between pure / side-effecting code, or stack-safe /
   stack-unsafe, is not enforced by the scala compiler. This requires
   developer discipline.
5. the developer community is still small. Getting help from the
   community can often be a slow process.

As with any new technology, there are rough edges that will be fixed
with time. Most of the problems are because there is a lack of
commercially-funded tooling in FP scala. If you see the benefit of FP,
you can help out by getting involved.

Although FP Scala cannot be as fast as streamlined Java using
mutation, the performance impact is unlikely to affect you if you're
already considering targetting the JVM. Measure the impact before
making a decision if it is important to you.

In the following chapters we are going to learn some of the vast
library of functionality provided by the ecosystem, how it is
organised and how you can find what you need (e.g. how did we know to
use =foldM= or =traverse= when we implemented =act=?). This will allow
us to complete the implementation of our application by building
additional layers of =@module=, use better alternatives to =Future=,
and remove redundancy that we've accidentally introduced.

* Backmatter                                                          :final:
:PROPERTIES:
:EXPORT_FILE_NAME: backmatter.md
:END:
{backmatter}
** Third Party Licenses

Some of the source code in this book has been copied from free / libre
software projects. The license of those projects require that the
following texts are distributed with the source that is presented in
this book.

*** Scala License

#+BEGIN_SRC
Copyright (c) 2002-2017 EPFL
Copyright (c) 2011-2017 Lightbend, Inc.

All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright notice,
    this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright notice,
    this list of conditions and the following disclaimer in the documentation
    and/or other materials provided with the distribution.
  * Neither the name of the EPFL nor the names of its contributors
    may be used to endorse or promote products derived from this software
    without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#+END_SRC

*** Scalaz License

#+BEGIN_SRC
Copyright (c) 2009-2014 Tony Morris, Runar Bjarnason, Tom Adams,
                        Kristian Domagala, Brad Clow, Ricky Clarkson,
                        Paul Chiusano, Trygve Laugstøl, Nick Partridge,
                        Jason Zaugg
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

1. Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
   notice, this list of conditions and the following disclaimer in the
   documentation and/or other materials provided with the distribution.
3. Neither the name of the copyright holder nor the names of
   its contributors may be used to endorse or promote products derived from
   this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#+END_SRC
*** Circe License

Circe is released under the [[http://www.apache.org/licenses/LICENSE-2.0][Apache 2.0]] and the following =NOTICE=

#+BEGIN_SRC
Copyright (c) 2015, Ephox Pty Ltd, Mark Hibberd, Sean Parsons,
                    Travis Brown, and other contributors.
All rights reserved.

Argonaut was initially developed to support products at Ephox.

Copyright (c) 2012, Ephox Pty Ltd, Mark Hibberd, Sean Parsons
                    and other contributors.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:

1. Redistributions of source code must retain the above copyright
   notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
   notice, this list of conditions and the following disclaimer in the
   documentation and/or other materials provided with the distribution.
3. The name of the author may not be used to endorse or promote products
   derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#+END_SRC
